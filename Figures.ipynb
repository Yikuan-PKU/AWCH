{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0375aa30",
   "metadata": {},
   "source": [
    "## C-H commutativiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap, SymLogNorm \n",
    "\n",
    "\n",
    "def set_publication_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',          \n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',      \n",
    "        'font.size': 20,                 \n",
    "        'axes.labelsize': 20,            \n",
    "        'axes.titlesize': 22,            \n",
    "        'xtick.labelsize': 20,           \n",
    "        'ytick.labelsize': 20,           \n",
    "        'legend.fontsize': 12,          \n",
    "        'figure.dpi': 300,               \n",
    "        'savefig.dpi': 300,              \n",
    "        'axes.linewidth': 2,           \n",
    "        'lines.linewidth': 2,               \n",
    "        'xtick.major.width': 2,       \n",
    "        'ytick.major.width': 2,\n",
    "        'xtick.direction': 'in',         \n",
    "        'ytick.direction': 'in',\n",
    "    })\n",
    "set_publication_style()\n",
    "def extract_diagonals(A, B, slice_range=None):\n",
    "    if slice_range is None:\n",
    "        slice_range = torch.arange(min(A.shape[0], B.shape[0]))\n",
    "    A = torch.flip(A, dims=[0,1])\n",
    "    B = torch.flip(B, dims=[0,1])\n",
    "    A_dense = torch.diag_embed(torch.diag(A)[slice_range])\n",
    "    B_dense = torch.diag_embed(torch.diag(B)[slice_range])\n",
    "    return A_dense, B_dense\n",
    "\n",
    "def compute_loglog_fit(A_dense, B_dense):\n",
    "    diag_a = A_dense.diag().detach().cpu().numpy()\n",
    "    diag_b = B_dense.diag().detach().cpu().numpy()\n",
    "    mask = (diag_a > 0) & (diag_b > 0)\n",
    "    if mask.sum() == 0:\n",
    "        return None, None, None, None\n",
    "    log_a, log_b = np.log10(diag_a[mask]), np.log10(diag_b[mask])\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(log_b, log_a)\n",
    "    return log_b, log_a, slope, r_value**2\n",
    "\n",
    "def compute_spearman_rank(A_dense, B_dense):\n",
    "    diag_a = A_dense.diag().detach().cpu().numpy()\n",
    "    diag_b = B_dense.diag().detach().cpu().numpy()\n",
    "    # define mask for idx>2000\n",
    "    # mask = np.arange(len(diag_a)) > 1000\n",
    "    mask = (diag_a > 0 ) & (diag_b > 0)\n",
    "    if mask.sum() < 2: return 0.0\n",
    "    correlation, _ = stats.spearmanr(diag_a[mask], diag_b[mask])\n",
    "    return correlation\n",
    "\n",
    "\n",
    "\n",
    "def compute_commutativity_random_baseline(A, B):\n",
    "    if A.ndim == 1: A = torch.diag(A)\n",
    "    if B.ndim == 1: B = torch.diag(B)\n",
    "    A, B = A.float().cpu(), B.float().cpu()\n",
    "\n",
    "    N = B.shape[0]\n",
    "    H = torch.randn(N, N, device=B.device)\n",
    "    Q, _ = torch.linalg.qr(H)\n",
    "\n",
    "    B_rand = Q @ B @ Q.T\n",
    "    \n",
    "    return compute_commutativity(A, B_rand)\n",
    "\n",
    "def compute_commutativity(A, B):\n",
    "    if A.ndim == 1: A = torch.diag(A)\n",
    "    if B.ndim == 1: B = torch.diag(B)\n",
    "    A, B = A.float().cpu(), B.float().cpu()\n",
    "    if A.shape != B.shape: return None \n",
    "    AB = torch.matmul(A, B)\n",
    "    BA = torch.matmul(B, A)\n",
    "    commutator = AB - BA\n",
    "    diff_norm = torch.norm(commutator, p='fro')\n",
    "    base_norm = torch.norm(AB, p='fro')\n",
    "    if base_norm == 0: return 0.0\n",
    "    return (diff_norm / base_norm).item()\n",
    "\n",
    "def compute_eigen_alignment(target_A, basis_B):\n",
    "    if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "    if basis_B.ndim == 1: basis_B = torch.diag(basis_B)\n",
    "    A, B = target_A.float().cpu(), basis_B.float().cpu()\n",
    "    try:\n",
    "        L_B, V_B = torch.linalg.eigh(B) \n",
    "    except:\n",
    "        return None \n",
    "    A_rotated = V_B.T @ A @ V_B\n",
    "    diag_energy = torch.norm(torch.diag(A_rotated), p=2)**2\n",
    "    total_energy = torch.norm(A_rotated, p='fro')**2\n",
    "    if total_energy == 0: return 0.0\n",
    "    return (diag_energy / total_energy).item()\n",
    "\n",
    "# def compute_split_commutativity(target_A, basis_B, top_k=100):\n",
    "#     if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "#     if basis_B.ndim == 1: basis_B = torch.diag(basis_B)\n",
    "#     A, B = target_A.float().cpu(), basis_B.float().cpu()\n",
    "#     try:\n",
    "#         L_B, V_B = torch.linalg.eigh(B)\n",
    "#         V_top = V_B[:, -top_k:]  \n",
    "#         P_top = V_top @ V_top.T\n",
    "#         I = torch.eye(B.shape[0], device=B.device)\n",
    "#         P_bulk = I - P_top\n",
    "#         Comm = A @ B - B @ A\n",
    "#         AB = A @ B \n",
    "#         num_top = torch.norm(P_top @ Comm @ P_top, p='fro')\n",
    "#         den_top = torch.norm(P_top @ AB @ P_top, p='fro')\n",
    "#         err_top = (num_top / (den_top )).item()\n",
    "#         num_bulk = torch.norm(P_bulk @ Comm @ P_bulk, p='fro')\n",
    "#         den_bulk = torch.norm(P_bulk @ AB @ P_bulk, p='fro')\n",
    "#         err_bulk = (num_bulk / (den_bulk )).item()\n",
    "#         return err_top, err_bulk\n",
    "#     except Exception as e:\n",
    "#         return None, None\n",
    "\n",
    "def compute_split_commutativity(target_A, basis_B, k=100, m=1500):\n",
    "\n",
    "    if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "    if basis_B.ndim == 1: basis_B = torch.diag(basis_B)\n",
    "    A, B = target_A.float().cpu(), basis_B.float().cpu()\n",
    "    \n",
    "    try:\n",
    "        L_B, V_B = torch.linalg.eigh(B)\n",
    "        N = V_B.shape[0]\n",
    "        \n",
    "        if k >= N: k = N // 10\n",
    "        if m > N: m = N\n",
    "        if m <= k: m = k + 100 \n",
    "        \n",
    "\n",
    "        V_top = V_B[:, -k:]\n",
    "        \n",
    "        V_bulk = V_B[:, -m:-k]\n",
    "        \n",
    "\n",
    "        P_top = V_top @ V_top.T\n",
    "        P_bulk = V_bulk @ V_bulk.T\n",
    "        \n",
    "\n",
    "        Comm = A @ B - B @ A\n",
    "        AB = A @ B \n",
    "        \n",
    "\n",
    "        num_top = torch.norm(P_top @ Comm @ P_top, p='fro')\n",
    "        den_top = torch.norm(P_top @ AB @ P_top, p='fro')\n",
    "        err_top = (num_top / (den_top )).item()\n",
    "        \n",
    "\n",
    "        num_bulk = torch.norm(P_bulk @ Comm @ P_bulk, p='fro')\n",
    "        den_bulk = torch.norm(P_bulk @ AB @ P_bulk, p='fro')\n",
    "        err_bulk = (num_bulk / (den_bulk)).item()\n",
    "        \n",
    "        return err_top, err_bulk\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in windowed commutativity: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "# def compute_scale_invariant_stats(target_A, basis_B):\n",
    "#     if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "#     if basis_B.ndim == 1: basis_B = torch.diag(basis_B)\n",
    "#     A, B = target_A.float().cpu(), basis_B.float().cpu()\n",
    "#     try:\n",
    "#         L_B, V_B = torch.linalg.eigh(B)\n",
    "#         # ÈôçÂ∫èÊéíÂàó\n",
    "#         idx_flip = torch.arange(L_B.shape[0] - 1, -1, -1)\n",
    "#         V_B = V_B[:, idx_flip]\n",
    "#         L_B = L_B[idx_flip]\n",
    "        \n",
    "#         # K: Raw projection\n",
    "#         K = V_B.T @ A @ V_B\n",
    "        \n",
    "#         # R: Normalized correlation (signed)\n",
    "#         diag_val = torch.abs(torch.diagonal(K))\n",
    "#         norm_factor = torch.sqrt(torch.outer(diag_val, diag_val))\n",
    "#         R = K / norm_factor \n",
    "#         R_abs = torch.abs(R) \n",
    "\n",
    "#         # Stats based on absolute value off-diagonal\n",
    "#         N = R.shape[0]\n",
    "#         mask_off = ~torch.eye(N, dtype=torch.bool)\n",
    "#         off_diag_elements = R_abs[mask_off]\n",
    "#         mean_coupling = torch.mean(off_diag_elements).item()\n",
    "#         var_coupling = torch.var(off_diag_elements).item()\n",
    "        \n",
    "#         return mean_coupling, var_coupling, R, K, L_B\n",
    "#     except Exception as e:\n",
    "#         return None, None, None, None, None\n",
    "def compute_scale_invariant_stats(target_A, basis_B):\n",
    "    if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "    if basis_B.ndim == 1: basis_B = torch.diag(basis_B)\n",
    "    \n",
    "    A = target_A.double().cpu()\n",
    "    B = basis_B.double().cpu()\n",
    "    \n",
    "    try:\n",
    "        L_B, V_B = torch.linalg.eigh(B)\n",
    "        \n",
    "        idx_flip = torch.arange(L_B.shape[0] - 1, -1, -1)\n",
    "        V_B = V_B[:, idx_flip]\n",
    "        L_B = L_B[idx_flip]\n",
    "        \n",
    "        # K: Raw projection (V_B^T @ A @ V_B)\n",
    "        K = V_B.T @ A @ V_B\n",
    "        \n",
    "        \n",
    "        diag_val = torch.abs(torch.diagonal(K))\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.outer(diag_val, diag_val))\n",
    "        \n",
    "\n",
    "        eps = 1e-38\n",
    "        \n",
    "\n",
    "        safe_mask = norm_factor > eps\n",
    "        \n",
    "        R = torch.zeros_like(K)\n",
    "        R[safe_mask] = K[safe_mask] / norm_factor[safe_mask]\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        R_abs = torch.abs(R) \n",
    "\n",
    "        N = R.shape[0]\n",
    "        mask_off = ~torch.eye(N, dtype=torch.bool)\n",
    "        off_diag_elements = R_abs[mask_off]\n",
    "        \n",
    "        mean_coupling = torch.mean(off_diag_elements).item()\n",
    "        var_coupling = torch.var(off_diag_elements).item()\n",
    "        \n",
    "        return mean_coupling, var_coupling, R.float(), K.float(), L_B.float()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in stats calculation: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_rmt_baseline_alignment(target_A):\n",
    "    if target_A.ndim == 1: target_A = torch.diag(target_A)\n",
    "    A = target_A.float().cpu()\n",
    "    N = A.shape[0]\n",
    "    H = torch.randn(N, N)\n",
    "    Q, _ = torch.linalg.qr(H)\n",
    "    A_rand = Q.T @ A @ Q\n",
    "    diag_energy = torch.norm(torch.diag(A_rand), p=2)**2\n",
    "    total_energy = torch.norm(A_rand, p='fro')**2\n",
    "    if total_energy == 0: return 0.0\n",
    "    return (diag_energy / total_energy).item()\n",
    "\n",
    "\n",
    "def analyze_epochs_advanced(epoch_list, base_path, slice_range, var_pairs):\n",
    "    results = {\n",
    "        \"slope\": {k: [] for k in var_pairs},\n",
    "        \"spearman\": {k: [] for k in var_pairs},\n",
    "        \"commutativity\": {k: [] for k in var_pairs},\n",
    "        \"comm_random\": {k: [] for k in var_pairs},\n",
    "        \"alignment\": {k: [] for k in var_pairs}, \n",
    "        \"rmt_alignment\": {k: [] for k in var_pairs},\n",
    "        \"comm_top\": {k: [] for k in var_pairs},\n",
    "        \"comm_bulk\": {k: [] for k in var_pairs},\n",
    "        \"mean_coupling\": {k: [] for k in var_pairs},\n",
    "        \"var_coupling\": {k: [] for k in var_pairs}\n",
    "    }\n",
    "\n",
    "    last_epoch_data = {}\n",
    "\n",
    "    for epoch in epoch_list:\n",
    "        file_path = f\"{base_path}{epoch}.pt\"\n",
    "        if not os.path.exists(file_path): continue\n",
    "        try:\n",
    "            loaded_data = torch.load(file_path, map_location='cpu')\n",
    "        except: continue\n",
    "\n",
    "        try:\n",
    "            L_H, V_H = torch.linalg.eigh(torch.tensor(loaded_data[\"Hessian\"]))\n",
    "        except:\n",
    "            V_H = None\n",
    "\n",
    "        for name, (key_a, key_b) in var_pairs.items():\n",
    "            if key_a not in loaded_data or key_b not in loaded_data: continue\n",
    "            \n",
    "            A_raw = torch.tensor(loaded_data[key_a]).float()\n",
    "            B_raw = torch.tensor(loaded_data[key_b]).float()\n",
    "            \n",
    "            A, B = A_raw, B_raw\n",
    "            if V_H is not None:\n",
    "                 if \"covar\" in key_a.lower(): A = V_H.transpose(-2, -1) @ A @ V_H\n",
    "                 if \"covar\" in key_b.lower(): B = V_H.transpose(-2, -1) @ B @ V_H\n",
    "                 if \"hessian\" in key_a.lower(): A = V_H.transpose(-2, -1) @ A @ V_H\n",
    "                 if \"hessian\" in key_b.lower(): B = V_H.transpose(-2, -1) @ B @ V_H\n",
    "\n",
    "            A_dense, B_dense = extract_diagonals(A, B, slice_range)\n",
    "            _, _, slope, r2 = compute_loglog_fit(A_dense, B_dense)\n",
    "            spearman = compute_spearman_rank(A_dense, B_dense)\n",
    "            \n",
    "            if slope is not None: \n",
    "                results[\"slope\"][name].append((epoch, slope))\n",
    "                results[\"spearman\"][name].append((epoch, spearman))\n",
    "\n",
    "            comm_val = compute_commutativity(A, B)\n",
    "            if comm_val is not None: \n",
    "                results[\"commutativity\"][name].append((epoch, comm_val))\n",
    "                comm_rand = compute_commutativity_random_baseline(A, B)\n",
    "                results[\"comm_random\"][name].append((epoch, comm_rand))\n",
    "\n",
    "            align_val = compute_eigen_alignment(target_A=A, basis_B=B)\n",
    "            if align_val is not None: results[\"alignment\"][name].append((epoch, align_val))\n",
    "            \n",
    "            rmt_val = compute_rmt_baseline_alignment(target_A=A)\n",
    "            results[\"rmt_alignment\"][name].append((epoch, rmt_val))\n",
    "            \n",
    "            err_top, err_bulk = compute_split_commutativity(target_A=A, basis_B=B, k=200, m=1000)\n",
    "            if err_top is not None:\n",
    "                results[\"comm_top\"][name].append((epoch, err_top))\n",
    "                results[\"comm_bulk\"][name].append((epoch, err_bulk))\n",
    "\n",
    "            mean_val, var_val, R_signed, K_matrix, L_B = compute_scale_invariant_stats(target_A=A, basis_B=B)\n",
    "            \n",
    "            if mean_val is not None:\n",
    "                results[\"mean_coupling\"][name].append((epoch, mean_val))\n",
    "                results[\"var_coupling\"][name].append((epoch, var_val))\n",
    "                \n",
    "                if epoch == epoch_list[-1]:\n",
    "                    if name not in last_epoch_data: last_epoch_data[name] = {}\n",
    "                    last_epoch_data[name]['K_matrix'] = K_matrix\n",
    "                    last_epoch_data[name]['R_matrix_signed'] = R_signed\n",
    "                    last_epoch_data[name]['mean_off_diag_real'] = mean_val\n",
    "                    last_epoch_data[name]['var_off_diag_real'] = var_val\n",
    "                    last_epoch_data[name]['A_raw'] = A_raw\n",
    "                    last_epoch_data[name]['B_raw'] = B_raw\n",
    "\n",
    "        del loaded_data\n",
    "\n",
    "    return results, last_epoch_data\n",
    "\n",
    "def plot_all_metrics(results, config):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    pair_names = list(results[\"slope\"].keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(pair_names)))\n",
    "    color_map = {name: colors[i] for i, name in enumerate(pair_names)}\n",
    "\n",
    "    ax = axes[0]\n",
    "    for name, data in results[\"slope\"].items():\n",
    "        if not data: continue\n",
    "        data.sort()\n",
    "        epochs, vals = zip(*data)\n",
    "        if \"C_\" in name:\n",
    "            dname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "        elif \"Covar_\" in name:\n",
    "            dname = \"$\\\\mathbf{Covar}$\"\n",
    "        elif \"C1_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "        elif \"C1_dia_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "        elif \"C1_dia_w_dia_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "        elif \"H2\" in name:\n",
    "            dname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "        ax.plot(epochs, vals, marker='o', label=dname, color=color_map[name])\n",
    "    ax.axhline(y=1, color='r', linestyle='--', linewidth=1.5, label=f\"Lower bound = {1}\")\n",
    "    ax.axhline(y=2, color='g', linestyle='--', linewidth=1.5, label=f\"Upper bound = {2}\")\n",
    "    ax.set_title(\"Power vs Epochs\")\n",
    "    ax.set_ylabel(\"$\\gamma$\")\n",
    "    ax.set_ylim(0.7, 2.3)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(fontsize='small')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax = axes[1]\n",
    "    \n",
    "    ax.axhline(y=1.0, color='gray', linestyle='-.', linewidth=1, alpha=0.5, label='Random Baseline (y=1)')\n",
    "    \n",
    "    for name in pair_names:\n",
    "        d_full = sorted(results[\"commutativity\"].get(name, []), key=lambda x: x[0])\n",
    "        d_top = sorted(results[\"comm_top\"].get(name, []), key=lambda x: x[0])\n",
    "        d_bulk = sorted(results[\"comm_bulk\"].get(name, []), key=lambda x: x[0])\n",
    "        d_rand = sorted(results[\"comm_random\"].get(name, []), key=lambda x: x[0])\n",
    "        \n",
    "        if not d_rand: continue\n",
    "        \n",
    "        rand_map = {e: v for e, v in d_rand}\n",
    "        \n",
    "        c = color_map[name]\n",
    "        \n",
    "        def get_ratio(data_list):\n",
    "            return [(e, v / rand_map[e]) for e, v in data_list if e in rand_map]\n",
    "        \n",
    "        r_full = get_ratio(d_full)\n",
    "        r_top = get_ratio(d_top)\n",
    "        r_bulk = get_ratio(d_bulk)\n",
    "        \n",
    "        if r_full: \n",
    "            ax.plot(*zip(*r_full), color=c, linestyle='-', linewidth=2, label=name) \n",
    "        if r_top: \n",
    "            ax.plot(*zip(*r_top), color=c, linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "        if r_bulk: \n",
    "            ax.plot(*zip(*r_bulk), color=c, linestyle=':', linewidth=2, alpha=0.9)\n",
    "\n",
    "    ax.set_title(\"Normalized Commutativity Error\\n(Ratio = Error / Random_Baseline)\")\n",
    "    ax.set_ylabel(\"Ratio (Log Scale)\")\n",
    "    ax.set_yscale('linear') \n",
    "    \n",
    "    \n",
    "    ax.grid(True, linestyle='--', alpha=0.6, which='both') # both grid for log scale\n",
    "    \n",
    "    from matplotlib.lines import Line2D\n",
    "    custom_lines = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-'),\n",
    "        Line2D([0], [0], color='black', lw=1.5, linestyle='--'),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle=':'),\n",
    "        Line2D([0], [0], color='gray', lw=1, linestyle='-.')\n",
    "    ]\n",
    "    ax.legend(custom_lines, ['Full Ratio', 'Top-K Ratio', 'Bulk Ratio', 'Random (y=1)'], loc='upper right', fontsize='small')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax = axes[2]\n",
    "    for name, data in results[\"spearman\"].items():\n",
    "        if not data: continue\n",
    "        data.sort()\n",
    "        epochs, vals = zip(*data)\n",
    "        ax.plot(epochs, vals, marker='s', markersize=4, label=name, color=color_map[name])\n",
    "    ax.set_title(\"Spearman Rank Correlation\")\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    ax = axes[3]\n",
    "    for name, data in results[\"alignment\"].items():\n",
    "        if not data: continue\n",
    "        data.sort()\n",
    "        epochs, vals = zip(*data)\n",
    "        ax.plot(epochs, vals, marker='o', markersize=4, label=name, color=color_map[name])\n",
    "        rmt_data = results[\"rmt_alignment\"].get(name, [])\n",
    "        if rmt_data:\n",
    "            rmt_data.sort()\n",
    "            ax.plot(*zip(*rmt_data), linestyle='--', alpha=0.5, color=color_map[name])\n",
    "    ax.set_title(\"Eigen Alignment (Solid=Real, Dashed=Random)\")\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    for ax in axes: ax.set_xlabel(\"Epoch\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"All_Metrics.pdf\"   \n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    plt.savefig(\n",
    "            save_path, \n",
    "            format='pdf',         \n",
    "            bbox_inches='tight',   \n",
    "            pad_inches=0.05,       \n",
    "            dpi=100               \n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_snapshot_deep_dive_combined(last_epoch_data, config):\n",
    "    cmap_choice = 'RdBu_r'\n",
    "    \n",
    "    names = list(last_epoch_data.keys())\n",
    "    n_rows = len(names)\n",
    "    n_cols = 3\n",
    "    \n",
    "    if n_rows == 0:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    figsize = (18, 5.0 * n_rows)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, constrained_layout=True)\n",
    "\n",
    "\n",
    "    if n_rows == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    print(f\"Generating combined plot for {n_rows} items...\")\n",
    "\n",
    "    for idx, (name, data) in enumerate(last_epoch_data.items()):\n",
    "        \n",
    "        K_real = data['K_matrix']\n",
    "        R_real = data['R_matrix_signed']\n",
    "        mean_real = data['mean_off_diag_real']\n",
    "        var_real = data['var_off_diag_real']\n",
    "        A_raw = data['A_raw']\n",
    "        B_raw = data['B_raw']\n",
    "\n",
    "        try:\n",
    "            L_A, _ = torch.linalg.eigh(A_raw)\n",
    "            N = A_raw.shape[0]\n",
    "            H = torch.randn(N, N)\n",
    "            Q, _ = torch.linalg.qr(H)\n",
    "            A_rand = Q @ torch.diag(L_A) @ Q.T\n",
    "            mean_rand, var_rand, R_rand, _, _ = compute_scale_invariant_stats(A_rand, B_raw)\n",
    "        except:\n",
    "            R_rand = None\n",
    "            mean_rand, var_rand = 0, 0\n",
    "\n",
    "        disp_dim = min(2560, R_real.shape[0])\n",
    "\n",
    "\n",
    "        ax = axes[idx, 0]\n",
    "        ax.grid(False)\n",
    "        k_data = K_real[:300, :300].numpy()\n",
    "        max_val_k = np.max(np.abs(k_data))\n",
    "        \n",
    "        linthresh = max_val_k * 1e-3 if max_val_k > 0 else 1e-5\n",
    "        norm = SymLogNorm(linthresh=linthresh, linscale=0.5, vmin=-max_val_k*5e-2, vmax=max_val_k*5e-2, base=10)\n",
    "        \n",
    "        im0 = ax.imshow(k_data, cmap=cmap_choice, norm=norm, interpolation='nearest')\n",
    "        \n",
    "        cbar0 = fig.colorbar(im0, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar0.set_label('Amplitude (SymLog)', weight='bold')\n",
    "\n",
    "        # LaTeX Title Logic\n",
    "        if \"C_\" in name: dname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "        elif \"Covar_\" in name: dname = \"$\\\\mathbf{Covar}$\"\n",
    "        elif \"C1_vs\" in name: dname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "        elif \"C1_dia_vs\" in name: dname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "        elif \"C1_dia_w_dia_vs\" in name: dname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "        elif \"H2\" in name: dname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "        else: dname = name.replace(\"_\", \" \") # Fallback\n",
    "\n",
    "        \n",
    "        ax.set_title(dname, pad=10)\n",
    "        ax.set_ylabel(\"Basis Index\") \n",
    "        \n",
    "        \n",
    "        if idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"Basis Index\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        # =========================================================\n",
    "        # Plot 2: Real Correlation R [Column 1]\n",
    "        # =========================================================\n",
    "        ax = axes[idx, 1]\n",
    "        ax.grid(False)\n",
    "        r_data = R_real[:disp_dim, :disp_dim].numpy()\n",
    "        im1 = ax.imshow(r_data, cmap=cmap_choice, vmin=-1, vmax=1, interpolation='nearest')\n",
    "        \n",
    "        cbar1 = fig.colorbar(im1, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar1.set_label('Correlation', weight='bold')\n",
    "        \n",
    "        ax.set_title(rf\"Normalized $R$ (Real)\" + f\"\\n$\\mu={mean_real:.4f} \\mid \\sigma^2={var_real:.2e}$\", pad=10)\n",
    "        ax.set_yticks([]) #\n",
    "        \n",
    "        if idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"Basis Index\")\n",
    "\n",
    "        # =========================================================\n",
    "        # Plot 3: Random Baseline R [Column 2]\n",
    "        # =========================================================\n",
    "        ax = axes[idx, 2]\n",
    "        ax.grid(False)\n",
    "        if R_rand is not None:\n",
    "            r_rand_data = R_rand[:disp_dim, :disp_dim].numpy()\n",
    "            im2 = ax.imshow(r_rand_data, cmap=cmap_choice, vmin=-1, vmax=1, interpolation='nearest') \n",
    "            \n",
    "            cbar2 = fig.colorbar(im2, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cbar2.set_label('Correlation', weight='bold')\n",
    "            \n",
    "            ax.set_title(rf\"Normalized $R$ (Random)\" + f\"\\n$\\mu={mean_rand:.4f} \\mid \\sigma^2={var_rand:.2e}$\", pad=10)\n",
    "            ax.set_yticks([]) \n",
    "            \n",
    "            if idx == n_rows - 1:\n",
    "                ax.set_xlabel(\"Basis Index\")\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "\n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    combined_name = \"Combined_Deep_Dive_Snapshot.pdf\"\n",
    "    save_path = os.path.join(save_dir, combined_name)\n",
    "    \n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf',\n",
    "        bbox_inches='tight',\n",
    "        pad_inches=0.1,\n",
    "        dpi=100\n",
    "    )\n",
    "    \n",
    "    print(f\"Saved combined vector figure to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "def plot_snapshot_deep_dive_v2(last_epoch_data, config):\n",
    "    cmap_choice = 'RdBu_r' \n",
    "\n",
    "    for name, data in last_epoch_data.items():\n",
    "        print(f\"\\n--- Deep Dive for {name} ---\")\n",
    "        \n",
    "        K_real = data['K_matrix']\n",
    "        R_real = data['R_matrix_signed']\n",
    "        mean_real = data['mean_off_diag_real']\n",
    "        var_real = data['var_off_diag_real']\n",
    "        A_raw = data['A_raw']\n",
    "        B_raw = data['B_raw']\n",
    "\n",
    "        try:\n",
    "            L_A, _ = torch.linalg.eigh(A_raw)\n",
    "            N = A_raw.shape[0]\n",
    "            H = torch.randn(N, N)\n",
    "            Q, _ = torch.linalg.qr(H)\n",
    "            A_rand = Q @ torch.diag(L_A) @ Q.T\n",
    "            mean_rand, var_rand, R_rand, _, _ = compute_scale_invariant_stats(A_rand, B_raw)\n",
    "        except:\n",
    "            R_rand = None\n",
    "            mean_rand, var_rand = 0, 0\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5.5), constrained_layout=True)\n",
    "        \n",
    "        disp_dim = min(2560, R_real.shape[0])\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # Plot 1: Raw Matrix K (SymLogNorm)\n",
    "        # ------------------------------------------------\n",
    "        ax = axes[0]\n",
    "        ax.grid(False)\n",
    "        k_data = K_real[:300, :300].numpy()\n",
    "        max_val_k = np.max(np.abs(k_data))\n",
    "        \n",
    "        linthresh = max_val_k * 1e-3 if max_val_k > 0 else 1e-5\n",
    "        norm = SymLogNorm(linthresh=linthresh, linscale=0.5, vmin=-max_val_k*5e-2, vmax=max_val_k*5e-2, base=10)\n",
    "        \n",
    "        im0 = ax.imshow(k_data, cmap=cmap_choice, norm=norm, interpolation='nearest')\n",
    "        \n",
    "        cbar0 = fig.colorbar(im0, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar0.set_label('Amplitude (SymLog)', weight='bold')\n",
    "        \n",
    "        if \"C_\" in name:\n",
    "            dname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "        elif \"Covar_\" in name:\n",
    "            dname = \"$\\\\mathbf{Covar}$\"\n",
    "        elif \"C1_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "        elif \"C1_dia_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "        elif \"C1_dia_w_dia_vs\" in name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "        elif \"H2\" in name:\n",
    "            dname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "        ax.set_title(dname, pad=10)\n",
    "        # ax.set_title(rf\"Raw Covariance \" + \"\\n(Log Scale)\", pad=10)\n",
    "\n",
    "        ax.set_xlabel(\"Basis Index\")\n",
    "        ax.set_ylabel(\"Basis Index \")\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        # Plot 2: Real Correlation R\n",
    "        # ------------------------------------------------\n",
    "        ax = axes[1]\n",
    "        ax.grid(False)\n",
    "        r_data = R_real[:disp_dim, :disp_dim].numpy()\n",
    "        im1 = ax.imshow(r_data, cmap=cmap_choice, vmin=-1, vmax=1, interpolation='nearest')\n",
    "        \n",
    "        cbar1 = fig.colorbar(im1, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar1.set_label('Correlation', weight='bold')\n",
    "        \n",
    "        ax.set_title(rf\"Normalized $R$ (Real)\" + f\"\\n$\\mu={mean_real:.4f} \\mid \\sigma^2={var_real:.2e}$\", pad=10)\n",
    "        ax.set_xlabel(\"Basis Index\")\n",
    "        # ax.set_ylabel(\"Basis Eigenmodes\") \n",
    "        ax.set_yticks([]) \n",
    "\n",
    "        # ------------------------------------------------\n",
    "        # Plot 3: Random Baseline R\n",
    "        # ------------------------------------------------\n",
    "        ax = axes[2]\n",
    "        ax.grid(False)\n",
    "        if R_rand is not None:\n",
    "            r_rand_data = R_rand[:disp_dim, :disp_dim].numpy()\n",
    "            im2 = ax.imshow(r_rand_data, cmap=cmap_choice, vmin=-1, vmax=1, interpolation='nearest') \n",
    "            \n",
    "            cbar2 = fig.colorbar(im2, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cbar2.set_label('Correlation', weight='bold')\n",
    "            \n",
    "            ax.set_title(rf\"Normalized $R$ (Random)\" + f\"\\n$\\mu={mean_rand:.4f} \\mid \\sigma^2={var_rand:.2e}$\", pad=10)\n",
    "            ax.set_xlabel(\"Basis Index\")\n",
    "            ax.set_yticks([]) \n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "\n",
    "        # plt.plot(np.diag(R_real), color='black', linewidth=0.5)  \n",
    "        # plt.suptitle(f\"Deep Dive Snapshot: {name}\", fontsize=16)\n",
    "\n",
    "        save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"{name}.pdf\"\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path, \n",
    "            format='pdf',         \n",
    "            bbox_inches='tight',   \n",
    "            pad_inches=0.05,       \n",
    "            dpi=100                \n",
    "        )\n",
    "        \n",
    "        print(f\"Saved vector figure to: {save_path}\")\n",
    "        \n",
    "        plt.show() \n",
    "        plt.close() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epoch_list =  [1, 10, 30, 50, 70, 80, 90, 100]#, 150, 200] \n",
    "    slice_range = torch.arange(0, 1500)\n",
    "    train_size = 2000\n",
    "    sample_number = 20\n",
    "\n",
    "    net_size = 50\n",
    "    n_class = 10\n",
    "    config = {}\n",
    "    config['lss_fn'] = 'mse'\n",
    "    config['dataset'] = 'mnist' \n",
    "    config['model'] = 'FC' \n",
    "    config['net_size'] = net_size\n",
    "    config['sample_holder'] = [i for i in range(n_class)]\n",
    "    config['B'] = 50\n",
    "    config['alpha'] = 0.1\n",
    "    save_dir = f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "    # save_dir = f\"./AWCH_data/NS{net_size}_TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "\n",
    "    file_name1 = \"C_epoch_\" \n",
    "    base_path1 = os.path.join(save_dir, file_name1)\n",
    "    \n",
    "    var_pairs = {\n",
    "\n",
    "\n",
    "        \"C_vs_H1\": (\"C\", \"H_1_d\"),\n",
    "        \"C1_vs_H1\": (\"C1\", \"H_1_d\"),\n",
    "        \"C1_dia_vs_H1\": (\"C1_dia\", \"H_1_d\"),\n",
    "        \"C1_dia_w_dia_vs_H1\": (\"C1_dia_w_dia\", \"H_1_d\"),\n",
    "        \"Covar_vs_Hessian\": (\"Covar\", \"Hessian\"),\n",
    "        \"H2_vs_H1\": (\"H_2_d\", \"H_1_d\"),\n",
    "\n",
    "    }\n",
    "\n",
    "    full_results, last_epoch_data = analyze_epochs_advanced(epoch_list, base_path1, slice_range, var_pairs)\n",
    "    plot_all_metrics(full_results, config)\n",
    "    if last_epoch_data:\n",
    "        plot_snapshot_deep_dive_combined(last_epoch_data, config)\n",
    "    pass\n",
    "\n",
    "    file_path1 = f\"{base_path1}{100}.pt\"\n",
    "    loaded_data1 = torch.load(file_path1)\n",
    "    \n",
    "    if 'train_loss_holder' in loaded_data1:\n",
    "        train_loss_holder = loaded_data1['train_loss_holder']\n",
    "        test_loss_holder = loaded_data1['test_loss_holder']\n",
    "        train_accuracy_holder = loaded_data1['train_accuracy_holder']\n",
    "        test_accuracy_holder = loaded_data1['test_accuracy_holder']\n",
    "        plt.plot(np.log10(train_loss_holder))\n",
    "        plt.plot(np.log10(test_loss_holder))\n",
    "        plt.title('loss')\n",
    "        plt.legend(['train','test'])\n",
    "        plt.show()\n",
    "        plt.plot(train_accuracy_holder)\n",
    "        plt.plot(test_accuracy_holder)\n",
    "        plt.title('accuracy')\n",
    "        plt.legend(['train','test'])\n",
    "        plt.show()\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383514e",
   "metadata": {},
   "source": [
    "## log-log Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2de2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def set_publication_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',          \n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',      \n",
    "        'font.size': 20,                 \n",
    "        'axes.labelsize': 20,           \n",
    "        'axes.titlesize': 22,           \n",
    "        'xtick.labelsize': 20,        \n",
    "        'ytick.labelsize': 20,         \n",
    "        'legend.fontsize': 12,        \n",
    "        'figure.dpi': 300,            \n",
    "        'savefig.dpi': 300,              \n",
    "        'axes.linewidth': 2,         \n",
    "        'lines.linewidth': 2,           \n",
    "        'xtick.major.width': 2,        \n",
    "        'ytick.major.width': 2,\n",
    "        'xtick.direction': 'in',       \n",
    "        'ytick.direction': 'in',\n",
    "    })\n",
    "set_publication_style()\n",
    "\n",
    "def extract_diagonals(A, B, slice_range=None):\n",
    "    if slice_range is None:\n",
    "        slice_range = torch.arange(min(A.shape[0], B.shape[0]))\n",
    "    A = torch.flip(A, dims=[0,1])\n",
    "    B = torch.flip(B, dims=[0,1])\n",
    "    A_dense = torch.diag_embed(torch.diag(A)[slice_range])\n",
    "    B_dense = torch.diag_embed(torch.diag(B)[slice_range])\n",
    "    return A_dense, B_dense\n",
    "\n",
    "def compute_loglog_fit(A_dense, B_dense):\n",
    "    diag_a = A_dense.diag().detach().cpu().numpy()\n",
    "    diag_b = B_dense.diag().detach().cpu().numpy()\n",
    "    \n",
    "    mask = (diag_a > 0) & (diag_b > 0)\n",
    "    if mask.sum() < 10:\n",
    "        return None, None, None, None\n",
    "        \n",
    "    log_a, log_b = np.log10(diag_a[mask]), np.log10(diag_b[mask])\n",
    "    \n",
    "    slope, intercept, r_value, _, _ = stats.linregress(log_b, log_a)\n",
    "    return log_b, log_a, slope, r_value**2\n",
    "\n",
    "def load_and_process_data(config, epoch, slice_range, var_pairs):\n",
    "    \n",
    "    train_size = config.get('train_size')\n",
    "    sample_number = config.get('sample_number')\n",
    "    class_num = config.get('class_number')\n",
    "    \n",
    "    save_dir = (f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_\"\n",
    "                f\"ClassN{class_num}_B{config['B']}lr{config['alpha']}_\"\n",
    "                f\"lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\")\n",
    "\n",
    "    base_path1 = os.path.join(save_dir, \"C_epoch_\") \n",
    "    base_path2 = os.path.join(save_dir, \"C_epoch_\") \n",
    "\n",
    "    file_path1 = f\"{base_path1}{epoch}.pt\"\n",
    "    file_path2 = f\"{base_path2}{epoch}.pt\"\n",
    "\n",
    "    if not os.path.exists(file_path1):\n",
    "        print(f\"‚ö†Ô∏è [Missing] {config['label']} -> Path not found: {save_dir}\")\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        loaded_data1 = torch.load(file_path1, map_location='cpu')\n",
    "        loaded_data2 = torch.load(file_path2, map_location='cpu')\n",
    "        loaded_data = {**loaded_data1, **loaded_data2}\n",
    "        del loaded_data1, loaded_data2\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå [Error] Loading {config['label']}: {e}\")\n",
    "        return {}\n",
    "\n",
    "    L, V = None, None\n",
    "    if \"Hessian\" in loaded_data:\n",
    "        try:\n",
    "            H_tensor = torch.tensor(loaded_data[\"Hessian\"])\n",
    "            L, V = torch.linalg.eigh(H_tensor.double()) \n",
    "            V = V.float()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Eigen decomposition failed: {e}\")\n",
    "\n",
    "    processed_results = {}\n",
    "\n",
    "    for name, (key_a, key_b) in var_pairs.items():\n",
    "        if key_a not in loaded_data or key_b not in loaded_data:\n",
    "            continue\n",
    "\n",
    "        A = torch.tensor(loaded_data[key_a])\n",
    "        B = torch.tensor(loaded_data[key_b])\n",
    "\n",
    "        if V is not None:\n",
    "            need_rotate_a = any(sub in key_a.lower() for sub in [\"covar\", \"hessian\"])\n",
    "            need_rotate_b = any(sub in key_b.lower() for sub in [\"covar\", \"hessian\"])\n",
    "            \n",
    "            if need_rotate_a: A = V.transpose(-2, -1) @ A @ V\n",
    "            if need_rotate_b: B = V.transpose(-2, -1) @ B @ V\n",
    "\n",
    "        A_dense, B_dense = extract_diagonals(A, B, slice_range)\n",
    "        log_b, log_a, slope, r2 = compute_loglog_fit(A_dense, B_dense)\n",
    "\n",
    "        if slope is not None:\n",
    "            log_a_centered = log_a - log_a.mean()\n",
    "            log_b_centered = log_b - log_b.mean()\n",
    "            \n",
    "            processed_results[name] = {\n",
    "                'x': log_b_centered,\n",
    "                'y': log_a_centered,\n",
    "                'slope': slope,\n",
    "                'r2': r2,\n",
    "                'label': config['label'],\n",
    "                'color': config.get('color', 'black')\n",
    "            }\n",
    "\n",
    "    del loaded_data\n",
    "    return processed_results\n",
    "\n",
    "def plot_shifted_loglog(results_list, var_pairs_to_plot, y_shift_step=1.5):\n",
    "\n",
    "\n",
    "    num_plots = len(var_pairs_to_plot)\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(6 * num_plots, 6))\n",
    "    \n",
    "    if num_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, (pair_name, (key_a, key_b)) in enumerate(var_pairs_to_plot.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        all_x = []\n",
    "        all_y = []\n",
    "\n",
    "        for config_idx, res_dict in enumerate(results_list):\n",
    "            if pair_name not in res_dict:\n",
    "                continue\n",
    "            \n",
    "            data = res_dict[pair_name]\n",
    "            x, y = data['x'], data['y']\n",
    "            slope, r2 = data['slope'], data['r2']\n",
    "            color = data['color']\n",
    "            label = data['label']\n",
    "\n",
    "            current_shift = config_idx * y_shift_step\n",
    "            y_shifted = y - current_shift\n",
    "            \n",
    "            ax.scatter(x, y_shifted, s=6, alpha=0.25, color=color, edgecolors='none')\n",
    "            \n",
    "            x_fit = np.array([x.min(), x.max()])\n",
    "            y_fit = slope * x_fit - current_shift \n",
    "\n",
    "            label_txt = f\"{label}\"\n",
    "            ax.plot(x_fit, y_fit, '-', lw=1, color=color, label=label_txt)\n",
    "\n",
    "            all_x.extend([x.min(), x.max()])\n",
    "            all_y.extend([y_shifted.min(), y_shifted.max()])\n",
    "\n",
    "        if all_x:\n",
    "            min_x, max_x = min(all_x), max(all_x)\n",
    "            min_y, max_y = min(all_y), max(all_y)\n",
    "            \n",
    "            cx = (min_x + max_x) / 2\n",
    "            cy = (min_y + max_y) / 2\n",
    "            \n",
    "            ref_x = np.array([min_x, max_x])\n",
    "            \n",
    "            # y - cy = k * (x - cx)  =>  y = k(x-cx) + cy\n",
    "            ax.plot(ref_x, 1.0 * (ref_x - cx) + cy, 'k--', lw=2, alpha=1, label='Slope=1 (Ref)')\n",
    "            ax.plot(ref_x, 2.0 * (ref_x - cx) + cy, 'k:', lw=2, alpha=1, label='Slope=2 (Ref)')\n",
    "            \n",
    "            ax.set_xlim(min_x - 0.5, max_x + 0.5)\n",
    "            ax.set_ylim(min_y - 0.5, max_y + 0.5)\n",
    "\n",
    "        if \"covar\" in key_a.lower():\n",
    "            pair_name = \"Empirical Covariance\"\n",
    "        elif \"h\" in key_a.lower():\n",
    "            pair_name = \"AWD-derived Covariance\"\n",
    "        ax.set_title(pair_name, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel(f\"Centered $\\log_{{10}}$({key_b})\")\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(f\"Shifted $\\log_{{10}}$({key_a})\")\n",
    "            \n",
    "        ax.legend(loc='lower right', frameon=True, framealpha=0.9, fontsize=14)\n",
    "        ax.grid(True, linestyle='--', alpha=1)\n",
    "        \n",
    "        ax.set_aspect('equal', adjustable='datalim')\n",
    "    \n",
    "        # plt.plot(np.diag(R_real), color='black', linewidth=0.5) \n",
    "        # plt.suptitle(f\"Deep Dive Snapshot: {name}\", fontsize=16)\n",
    "\n",
    "    save_dir = f\"ICML_Figures\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"loglog.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf',         \n",
    "        bbox_inches='tight',  \n",
    "        pad_inches=0.05,       \n",
    "        dpi=300                \n",
    "    )\n",
    "    \n",
    "    print(f\"Saved vector figure to: {save_path}\")\n",
    "    \n",
    "    plt.show() #\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================\n",
    "# üîß Main Execution\n",
    "# ============================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    epoch_to_plot = 100\n",
    "    slice_range = torch.arange(0, 1500) \n",
    "    \n",
    "\n",
    "    var_pairs_to_plot = {\n",
    "        \"Covar vs Hessian\": (\"Covar\", \"Hessian\"),\n",
    "        \"H_2 vs Hessian\": (\"H_2_d\", \"Hessian\"), \n",
    "        # \"Covar vs H_2\": (\"Covar\", \"H_2_d\"),\n",
    "        # \"H_1 vs Hessian\": (\"H_1_d\", \"Hessian\"),\n",
    "    }\n",
    "\n",
    "    configs = [\n",
    "        {\n",
    "            'label': 'CNN/CIFAR10/CSE',\n",
    "            'lss_fn': 'cse',\n",
    "            'dataset': 'cifar10',\n",
    "            'model': 'CNN',\n",
    "            'B': 128,          \n",
    "            'alpha': 0.1,      \n",
    "            'train_size': 2000,\n",
    "            'sample_number': 20,\n",
    "            'class_number': 10,\n",
    "            'color': '#1f77b4' \n",
    "        },\n",
    "        {\n",
    "            'label': 'MLP/MNIST/CSE',\n",
    "            'lss_fn': 'cse',\n",
    "            'dataset': 'mnist',\n",
    "            'model': 'FC',\n",
    "            'B': 50,          \n",
    "            'alpha': 0.1,\n",
    "            'train_size': 2000,\n",
    "            'sample_number': 20,\n",
    "            'class_number': 10,\n",
    "            'color': '#d62728'\n",
    "        },\n",
    "        {\n",
    "            'label': 'MLP/MNIST/MSE',\n",
    "            'lss_fn': 'mse',\n",
    "            'dataset': 'mnist',\n",
    "            'model': 'FC',\n",
    "            'B': 50,           \n",
    "            'alpha': 0.1,\n",
    "            'train_size': 2000,\n",
    "            'sample_number': 20,\n",
    "            'class_number': 10,\n",
    "            'color': '#2ca02c'\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    print(f\"--- Starting Analysis for Epoch {epoch_to_plot} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    for cfg in configs:\n",
    "        print(f\"Processing: {cfg['label']}...\")\n",
    "        data = load_and_process_data(cfg, epoch_to_plot, slice_range, var_pairs_to_plot)\n",
    "        results_list.append(data)\n",
    "\n",
    "\n",
    "    if any(results_list):\n",
    "        plot_shifted_loglog(results_list, var_pairs_to_plot, y_shift_step=1.5)\n",
    "    else:\n",
    "        print(\"‚ùå No data loaded. Please check your folder paths and naming convention.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "\n",
    "def set_publication_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',\n",
    "        'font.size': 20,\n",
    "        'axes.labelsize': 20,\n",
    "        'axes.titlesize': 22,\n",
    "        'xtick.labelsize': 20,\n",
    "        'ytick.labelsize': 20,\n",
    "        'legend.fontsize': 12,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'axes.linewidth': 2,\n",
    "        'lines.linewidth': 2,\n",
    "        'xtick.major.width': 2,\n",
    "        'ytick.major.width': 2,\n",
    "        'xtick.direction': 'in',\n",
    "        'ytick.direction': 'in',\n",
    "    })\n",
    "set_publication_style()\n",
    "\n",
    "def get_rotated_diagonal_decay(target_tensor, basis_tensor=None, top_k=1500, exclude_first=20):\n",
    "    \n",
    "    if basis_tensor is None:\n",
    "        try:\n",
    "            vals = torch.linalg.eigvalsh(target_tensor.double())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Eigen decomposition failed: {e}\")\n",
    "            return None, None, None, None\n",
    "    else:\n",
    "        try:\n",
    "            # Hessian = V * L * V.T\n",
    "            L_h, V_h = torch.linalg.eigh(basis_tensor.double())\n",
    "            \n",
    "            target_double = target_tensor.double()\n",
    "            # Diag(V^T C V)\n",
    "            rotated_matrix = V_h.T @ target_double @ V_h\n",
    "            vals = torch.diag(rotated_matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Basis decomposition failed: {e}\")\n",
    "            return None, None, None, None\n",
    "\n",
    "    vals = vals.detach().cpu().numpy()\n",
    "\n",
    "    vals = np.sort(vals)[::-1]\n",
    "    \n",
    "    if top_k is not None and top_k < len(vals):\n",
    "        vals = vals[:top_k]\n",
    "    \n",
    "    ranks = np.arange(1, len(vals) + 1)\n",
    "    \n",
    "    mask = vals > 1e-20\n",
    "    if mask.sum() < exclude_first + 10:\n",
    "        return None, None, None, None\n",
    "\n",
    "    valid_vals = vals[mask]\n",
    "    valid_ranks = ranks[mask]\n",
    "\n",
    "    log_ranks = np.log10(valid_ranks)\n",
    "    log_vals = np.log10(valid_vals)\n",
    "\n",
    "\n",
    "    log_vals_centered = log_vals - np.mean(log_vals)\n",
    "\n",
    "    if len(log_ranks) > exclude_first:\n",
    "        fit_x = log_ranks[exclude_first:800]\n",
    "        fit_y = log_vals_centered[exclude_first:800] \n",
    "    else:\n",
    "        fit_x = log_ranks\n",
    "        fit_y = log_vals_centered\n",
    "\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(fit_x, fit_y)\n",
    "    r2 = r_value**2\n",
    "    \n",
    "    fit_line_y = slope * fit_x + intercept\n",
    "\n",
    "    return {\n",
    "        'all_x': log_ranks,\n",
    "        'all_y': log_vals_centered,  \n",
    "        'fit_y_pred': fit_line_y,\n",
    "        'slope': slope,\n",
    "        'r2': r2,\n",
    "        'exclude_idx': exclude_first\n",
    "    }\n",
    "\n",
    "def load_and_analyze(config, epoch, analysis_pairs, top_k=1500, exclude_first=20):\n",
    "    \n",
    "    train_size = config.get('train_size')\n",
    "    sample_number = config.get('sample_number')\n",
    "    class_num = config.get('class_number')\n",
    "    \n",
    "    save_dir = (f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_\"\n",
    "                f\"ClassN{class_num}_B{config['B']}lr{config['alpha']}_\"\n",
    "                f\"lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\")\n",
    "\n",
    "    base_path = os.path.join(save_dir, \"C_epoch_\") \n",
    "    file_path = f\"{base_path}{epoch}.pt\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è Path not found: {save_dir}\")\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        loaded_data = torch.load(file_path, map_location='cpu')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error Loading: {e}\")\n",
    "        return {}\n",
    "\n",
    "    processed_results = {}\n",
    "\n",
    "    for plot_name, (target_key, basis_key) in analysis_pairs.items():\n",
    "        if target_key not in loaded_data: continue\n",
    "        \n",
    "        target_tensor = torch.tensor(loaded_data[target_key])\n",
    "        basis_tensor = None\n",
    "        if basis_key is not None:\n",
    "            if basis_key in loaded_data:\n",
    "                basis_tensor = torch.tensor(loaded_data[basis_key])\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        res = get_rotated_diagonal_decay(\n",
    "            target_tensor, basis_tensor, top_k=top_k, exclude_first=exclude_first\n",
    "        )\n",
    "        \n",
    "        if res is not None:\n",
    "            res['label'] = config['label']\n",
    "            res['color'] = config.get('color', 'black')\n",
    "            processed_results[plot_name] = res\n",
    "\n",
    "    del loaded_data\n",
    "    return processed_results\n",
    "\n",
    "\n",
    "def plot_centered_comparison(results_list, analysis_pairs, y_shift_step=2.0, top_k=1500):\n",
    "    \n",
    "    num_plots = len(analysis_pairs)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(6 * num_plots, 7), \n",
    "                             sharey=True, sharex=True)\n",
    "    \n",
    "    if num_plots == 1: axes = [axes]\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "    for idx, (plot_name, _) in enumerate(analysis_pairs.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "\n",
    "        for config_idx, res_dict in enumerate(results_list):\n",
    "            if plot_name not in res_dict: continue\n",
    "            \n",
    "            data = res_dict[plot_name]\n",
    "            \n",
    "            all_x = data['all_x']\n",
    "            all_y = data['all_y'] \n",
    "            fit_x = data['fit_x']\n",
    "            fit_y_pred = data['fit_y_pred']\n",
    "            slope = data['slope']\n",
    "            color = data['color']\n",
    "            label = data['label']\n",
    "\n",
    "            shift = config_idx * y_shift_step\n",
    "            all_y_shifted = all_y - shift\n",
    "            fit_y_pred_shifted = fit_y_pred - shift\n",
    "            \n",
    "            label_txt = f\"{label} \"\n",
    "            ax.scatter(all_x, all_y_shifted, s=10, color=color, alpha=0.5, edgecolors='none',label=label_txt)\n",
    "            \n",
    "            # alpha_val = -slope\n",
    "            \n",
    "            # ax.plot(fit_x, fit_y_pred_shifted, '--', lw=2.5, color=color, label=label_txt)\n",
    "\n",
    "        ax.set_title(plot_name, fontweight='bold', pad=12)\n",
    "        ax.set_xlabel(r\"$\\log_{10}(\\text{Rank})$\")\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(r\"Centered $\\log_{10}(\\text{Value})$ (Shifted)\")\n",
    "\n",
    "        ax.legend(loc='lower left', frameon=True, fontsize=18, framealpha=1)\n",
    "        ax.grid(True, linestyle='--', alpha=1)\n",
    "\n",
    "    save_path = f\"ICML_Figures/centered_decay_comparison_top{top_k}.pdf\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.savefig(save_path, format='pdf', bbox_inches='tight', pad_inches=0.05, dpi=300)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    epoch_to_plot = 100\n",
    "    top_k = 1000\n",
    "    exclude_outliers = 20  \n",
    "\n",
    "\n",
    "    analysis_pairs = {\n",
    "        \"Hessian Spectra\": (\"Hessian\", None), \n",
    "        \"Covar Diagonals (in Hessian Basis)\": (\"Covar\", \"Hessian\"),\n",
    "    }\n",
    "\n",
    "\n",
    "    configs = [\n",
    "        {\n",
    "            'label': 'CNN/CIFAR10/CSE',\n",
    "            'lss_fn': 'cse', 'dataset': 'cifar10', 'model': 'CNN',\n",
    "            'B': 128, 'alpha': 0.1, 'train_size': 2000, \n",
    "            'sample_number': 20, 'class_number': 10, 'color': '#1f77b4' # Blue\n",
    "        },\n",
    "        {\n",
    "            'label': 'MLP/MNIST/CSE',\n",
    "            'lss_fn': 'cse', 'dataset': 'mnist', 'model': 'FC',\n",
    "            'B': 50, 'alpha': 0.1, 'train_size': 2000, \n",
    "            'sample_number': 20, 'class_number': 10, 'color': '#d62728' # Red\n",
    "        },\n",
    "        {\n",
    "            'label': 'MLP/MNIST/MSE',\n",
    "            'lss_fn': 'mse', 'dataset': 'mnist', 'model': 'FC',\n",
    "            'B': 50, 'alpha': 0.1, 'train_size': 2000, \n",
    "            'sample_number': 20, 'class_number': 10, 'color': '#2ca02c' # Green\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    print(f\"--- Processing Epoch {epoch_to_plot} ---\")\n",
    "    \n",
    "    results = []\n",
    "    for cfg in configs:\n",
    "        print(f\"Loading {cfg['label']}...\")\n",
    "        results.append(load_and_analyze(cfg, epoch_to_plot, analysis_pairs, top_k, exclude_outliers))\n",
    "\n",
    "    if any(results):\n",
    "\n",
    "        plot_centered_comparison(results, analysis_pairs, y_shift_step=2.5, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3126149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "def set_publication_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',          \n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',     \n",
    "        'font.size': 20,                \n",
    "        'axes.labelsize': 20,            \n",
    "        'axes.titlesize': 22,            \n",
    "        'xtick.labelsize': 20,          \n",
    "        'ytick.labelsize': 20,          \n",
    "        'legend.fontsize': 12,          \n",
    "        'figure.dpi': 300,             \n",
    "        'savefig.dpi': 300,             \n",
    "        'axes.linewidth': 2,          \n",
    "        'lines.linewidth': 2,         \n",
    "        'xtick.major.width': 2,    \n",
    "        'ytick.major.width': 2,\n",
    "        'xtick.direction': 'in',         \n",
    "        'ytick.direction': 'in',\n",
    "    })\n",
    "set_publication_style()\n",
    "\n",
    "def compute_frobenius_norm(matrix, slice_range=None):\n",
    "    return torch.norm(torch.tensor(matrix), p='fro').item()\n",
    "\n",
    "def get_diag_elements(matrix, slice_range=None):\n",
    "\n",
    "    t = torch.tensor(matrix)\n",
    "    if t.ndim == 1:\n",
    "        diag = t\n",
    "    else:\n",
    "        diag = torch.diag(t)\n",
    "    \n",
    "\n",
    "    diag = torch.flip(diag, dims=[0]) \n",
    "\n",
    "    if slice_range is not None:\n",
    "        slice_idx = slice_range.long()\n",
    "        valid_mask = slice_idx < len(diag)\n",
    "        valid_idx = slice_idx[valid_mask]\n",
    "        return diag[valid_idx].cpu().numpy(), valid_idx.cpu().numpy()\n",
    "    \n",
    "    return diag.cpu().numpy(), np.arange(len(diag))\n",
    "\n",
    "def analyze_data(epoch_list, base_path, matrix_keys, slice_range=None):\n",
    "\n",
    "    norm_results = {key: [] for key in matrix_keys}\n",
    "    last_epoch_data = None\n",
    "    \n",
    "    for epoch in epoch_list:\n",
    "        file_path = f\"{base_path}{epoch}.pt\"\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            loaded_data = torch.load(file_path, map_location='cpu')\n",
    "            \n",
    "            if epoch == epoch_list[-1]:\n",
    "                last_epoch_data = loaded_data\n",
    "\n",
    "            for key in matrix_keys:\n",
    "                if key in loaded_data:\n",
    "                    fnorm = compute_frobenius_norm(loaded_data[key], slice_range=slice_range)\n",
    "                    norm_results[key].append((epoch, fnorm))\n",
    "            \n",
    "            if epoch != epoch_list[-1]:\n",
    "                del loaded_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error Loading Epoch {epoch}: {e}\")\n",
    "    for key in norm_results:\n",
    "        norm_results[key] = sorted(norm_results[key], key=lambda x: x[0])\n",
    "\n",
    "    loss_data = []\n",
    "    acc_data = []\n",
    "    diag_data = {} \n",
    "\n",
    "    if last_epoch_data:\n",
    "        # Loss & Acc\n",
    "        if 'train_loss_holder' in last_epoch_data: raw_loss = last_epoch_data['train_loss_holder']\n",
    "        elif 'loss' in last_epoch_data: raw_loss = last_epoch_data['loss']\n",
    "        else: raw_loss = []\n",
    "        \n",
    "        if 'train_accuracy_holder' in last_epoch_data: raw_acc = last_epoch_data['train_accuracy_holder']\n",
    "        elif 'acc' in last_epoch_data: raw_acc = last_epoch_data['acc']\n",
    "        else: raw_acc = []\n",
    "\n",
    "        if isinstance(raw_loss, torch.Tensor): loss_data = raw_loss.cpu().numpy().tolist()\n",
    "        elif isinstance(raw_loss, list): loss_data = raw_loss\n",
    "        \n",
    "        if isinstance(raw_acc, torch.Tensor): acc_data = raw_acc.cpu().numpy().tolist()\n",
    "        elif isinstance(raw_acc, list): acc_data = raw_acc\n",
    "        \n",
    "        # Diagonals\n",
    "        target_keys = [\"C\", \"C1\", \"C2\", \"C3\", \"C1_dia\", \"C1_dia_w_dia\"]\n",
    "        for key in target_keys:\n",
    "            if key in last_epoch_data:\n",
    "                values, indices = get_diag_elements(last_epoch_data[key], slice_range)\n",
    "                diag_data[key] = (values, indices)\n",
    "        \n",
    "        del last_epoch_data \n",
    "\n",
    "    return norm_results, loss_data, acc_data, diag_data\n",
    "\n",
    "\n",
    "def plot_results(norm_results, loss_data, acc_data, diag_data, config):\n",
    "    \n",
    "    colors = plt.cm.tab10.colors \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 9))\n",
    "    \n",
    "    ax_norm = axes[0, 0]    # 1. Top-Left\n",
    "    ax_scatter1 = axes[0, 1]# 2. Top-Right\n",
    "    ax_loss = axes[1, 0]    # 3. Bottom-Left\n",
    "    ax_scatter2 = axes[1, 1]# 4. Bottom-Right\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. Frobenius Norm Evolution (Top-Left)\n",
    "    # ==========================================\n",
    "    idx = 0\n",
    "    for name, data in norm_results.items():\n",
    "        if not data: continue\n",
    "        epochs = [x[0] for x in data]\n",
    "        norms = [x[1] for x in data]\n",
    "        if \"C\" == name:\n",
    "            dname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "        elif \"Covar\" == name:\n",
    "            dname = \"$\\\\mathbf{Covar}$\"\n",
    "        elif \"C1\" == name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "        elif \"C1_dia\" ==   name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "        elif \"C1_dia_w_dia\" == name:\n",
    "            dname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "        elif \"H2\" == name:\n",
    "            dname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "        elif \"C2\" == name:\n",
    "            dname = \"$\\\\mathbf{C}^{hg}$\"\n",
    "        elif \"C3\" == name:\n",
    "            dname = \"$\\\\mathbf{C}^{gg}$\"  \n",
    "        ax_norm.semilogy(epochs, norms, marker='o', markersize=4, \n",
    "                         label=dname, color=colors[idx % len(colors)])\n",
    "        idx += 1\n",
    "    \n",
    "    ax_norm.set_title(\"Frobenius Norm Evolution\")\n",
    "    ax_norm.set_xlabel(\"Epoch\")\n",
    "    ax_norm.set_ylabel(r\"$\\|\\mathbf{M}\\|_F$\")\n",
    "    ax_norm.legend(loc='lower center', frameon=False, fancybox=False, edgecolor='black', fontsize=16)\n",
    "    ax_norm.grid(True, which=\"minor\", linestyle=':', alpha=0.2)\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. Loss & Accuracy (Bottom-Left)\n",
    "    # ==========================================\n",
    "    if loss_data or acc_data:\n",
    "        epochs_range = range(1, len(loss_data) + 1) if loss_data else range(1, len(acc_data) + 1)\n",
    "        \n",
    "        color_loss = '#D62728' \n",
    "        ax_loss.set_xlabel('Epoch')\n",
    "        ax_loss.set_ylabel('Training Loss', color=color_loss, fontweight='bold')\n",
    "        l1 = None\n",
    "        if loss_data:\n",
    "            l1, = ax_loss.semilogy(epochs_range, loss_data, color=color_loss, linewidth=1, alpha=0.9, label='Loss')\n",
    "        ax_loss.tick_params(axis='y', labelcolor=color_loss)\n",
    "        ax_loss.grid(True, which=\"minor\", linestyle=':', alpha=0.2)\n",
    "\n",
    "        ax_acc = ax_loss.twinx()\n",
    "        color_acc = '#1F77B4' \n",
    "        ax_acc.set_ylabel('Training Accuracy', color=color_acc, fontweight='bold')\n",
    "        l2 = None\n",
    "        if acc_data:\n",
    "            curr_range = range(1, len(acc_data) + 1)\n",
    "            l2, = ax_acc.plot(curr_range, acc_data, color=color_acc, linewidth=1, alpha=0.9, label='Acc')\n",
    "        ax_acc.tick_params(axis='y', labelcolor=color_acc)\n",
    "        \n",
    "        lines, labels = [], []\n",
    "        if l1: lines.append(l1); labels.append(\"Loss\")\n",
    "        if l2: lines.append(l2); labels.append(\"Accuracy\")\n",
    "        if lines:\n",
    "            ax_loss.legend(lines, labels, loc='center right', frameon=False, fancybox=False, edgecolor='black', fontsize=16)\n",
    "        ax_loss.set_title(\"Training Loss & Accuracy\")\n",
    "        ax_loss.grid(True, which=\"minor\", linestyle=':', alpha=0.2)\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_components_vs_c(ax):\n",
    "        if \"C\" not in diag_data: return\n",
    "        c_vals, indices = diag_data[\"C\"]\n",
    "        c_denom = c_vals \n",
    "        \n",
    "        keys = [\"C1\", \"C2\", \"C3\"]\n",
    "        local_idx = 0\n",
    "        for key in keys:\n",
    "            if key not in diag_data: continue\n",
    "            vals, _ = diag_data[key]\n",
    "            \n",
    "            ratio = vals / c_denom\n",
    "\n",
    "            if \"C1\" in key:\n",
    "                dname = \"$C_{ii}^{hh}/C_{AWD,raw,ii}$\"\n",
    "            elif \"C2\" in key:\n",
    "                dname = \"$C_{ii}^{hg}/C_{AWD,raw,ii}$\"\n",
    "            elif \"C3\" in key:\n",
    "                dname = \"$C_{ii}^{gg}/C_{AWD,raw,ii}$\"\n",
    "\n",
    "            ax.scatter(indices, ratio, s=10, alpha=0.8, \n",
    "                       label=dname, color=colors[local_idx % 10])\n",
    "            local_idx += 1\n",
    "        \n",
    "        ax.set_title(r\"Components Magnitude at epoch=100\")\n",
    "        ax.set_xlabel(\"Ascending Index\")\n",
    "        ax.set_ylabel(\"Ratio value\")\n",
    "        ax.legend(loc='center left', frameon=False, fancybox=False, edgecolor='black', fontsize=16)\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    def plot_approx_check(ax):\n",
    "        if \"C1\" not in diag_data: return\n",
    "        c_vals, indices = diag_data[\"C1\"]\n",
    "        c_denom = c_vals \n",
    "\n",
    "\n",
    "        # 2. C1_dia / C\n",
    "        if \"C1_dia\" in diag_data:\n",
    "            c1_dia_vals, _ = diag_data[\"C1_dia\"]\n",
    "            ratio_c1_dia = c1_dia_vals / c_denom\n",
    "            ax.scatter(indices, ratio_c1_dia, s=10, alpha=0.8, \n",
    "                       label=\"$C_{ii}^{hh,SD}/C_{ii}^{hh}$\", color=colors[0]) \n",
    "\n",
    "            if \"C1_dia_w_dia\" in diag_data:\n",
    "                c1_dia_w_dia_vals, _ = diag_data[\"C1_dia_w_dia\"]\n",
    "                \n",
    "                ratio_inter = c1_dia_vals / (c1_dia_w_dia_vals )\n",
    "                \n",
    "                ax.scatter(indices, ratio_inter, s=10, alpha=0.8, marker='^',\n",
    "                           label=\"$C_{ii}^{hh,SD}/C_{ii}^{hh,SD,WD}$\", color=colors[2]) \n",
    "\n",
    "        ax.set_title(r\"Approximations Check at epoch=100\")\n",
    "        ax.set_xlabel(\"Ascending Index\")\n",
    "        ax.set_ylabel(\"Ratio value\")\n",
    "        ax.legend(loc='lower left', frameon=False, fancybox=False, edgecolor='black', fontsize=16)\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.set_ylim(0, 1.5)\n",
    "\n",
    "    plot_components_vs_c(ax_scatter1)\n",
    "    plot_approx_check(ax_scatter2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"C_approx_com.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf',         \n",
    "        bbox_inches='tight',   \n",
    "        pad_inches=0.05,       \n",
    "        dpi=100               \n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epoch_list = [1, 10, 30, 50, 70, 80, 90, 100]\n",
    "    slice_range = torch.arange(0, 1500) \n",
    "    \n",
    "    train_size = 2000\n",
    "    sample_number = 20\n",
    "    config = {}\n",
    "    config['lss_fn'] = 'mse'\n",
    "    config['dataset'] = 'mnist'\n",
    "    config['model'] = 'FC'\n",
    "    config['sample_holder'] = [0,1,2,3,4,5,6,7,8,9]\n",
    "    config['class_number'] = 10\n",
    "    config['B'] = 50\n",
    "    config['alpha'] = 0.1\n",
    "    \n",
    "    save_dir = f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "    file_name = \"C_epoch_\"\n",
    "    base_path = os.path.join(save_dir, file_name)\n",
    "    \n",
    "    matrix_keys = [\"C\", \"C1\", \"C2\", \"C3\", \"C1_dia\", \"C1_dia_w_dia\"]\n",
    "\n",
    "    norm_results, loss_data, acc_data, diag_data = analyze_data(epoch_list, base_path, matrix_keys, slice_range=slice_range)\n",
    "    \n",
    "    plot_results(norm_results, loss_data, acc_data, diag_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "from zmq import NORM_SEGMENT_SIZE\n",
    "\n",
    "\n",
    "def apply_icml_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',\n",
    "        'font.size': 13,\n",
    "        'axes.labelsize': 15,\n",
    "        'axes.titlesize': 13,\n",
    "        'xtick.labelsize': 11,\n",
    "        'ytick.labelsize': 11,\n",
    "        'legend.fontsize': 9,\n",
    "        'lines.linewidth': 0.5,\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'grid.linestyle': '--',\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "    })\n",
    "\n",
    "\n",
    "def extract_diagonals(A, B, slice_range=None):\n",
    "    if slice_range is None:\n",
    "        slice_range = torch.arange(min(A.shape[0], B.shape[0]))\n",
    "    A = torch.flip(A, dims=[0, 1])\n",
    "    B = torch.flip(B, dims=[0, 1])\n",
    "    diag_a_val = torch.diag(A)[slice_range]\n",
    "    diag_b_val = torch.diag(B)[slice_range]\n",
    "    return diag_a_val, diag_b_val\n",
    "\n",
    "def load_and_merge_data(epoch, base_path1, base_path2):\n",
    "    file_path1 = f\"{base_path1}{epoch}.pt\"\n",
    "    file_path2 = f\"{base_path2}{epoch}.pt\"\n",
    "    \n",
    "    if not os.path.exists(file_path1) or not os.path.exists(file_path2):\n",
    "        pass \n",
    "\n",
    "    try:\n",
    "        if os.path.exists(file_path1):\n",
    "            d1 = torch.load(file_path1, map_location='cpu')\n",
    "        else:\n",
    "            d1 = {}\n",
    "        \n",
    "        if os.path.exists(file_path2):\n",
    "            d2 = torch.load(file_path2, map_location='cpu')\n",
    "        else:\n",
    "            d2 = {}\n",
    "            \n",
    "        data = {**d1, **d2}\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error Loading Data: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_loglog_fit_simple(x, y):\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "    return slope, intercept, r_value**2\n",
    "\n",
    "\n",
    "def clean_tex_label(text):\n",
    "\n",
    "    return text.replace(\"_\", r\"\\_\")\n",
    "    \n",
    "\n",
    "def _plot_scatter_on_ax(ax, data_dict, hessian_eig, var_pair, slice_range):\n",
    "\n",
    "    key_a, key_b = var_pair\n",
    "    \n",
    "    if key_a not in data_dict or key_b not in data_dict:\n",
    "        ax.text(0.5, 0.5, \"Missing Data\", ha='center', va='center')\n",
    "        return\n",
    "\n",
    "    A = torch.tensor(data_dict[key_a])\n",
    "    B = torch.tensor(data_dict[key_b])\n",
    "    \n",
    "    L, V = hessian_eig\n",
    "    if \"covar\" in key_a.lower() or \"hessian\" in key_a.lower():\n",
    "        A = V.transpose(-2, -1) @ A @ V\n",
    "    if \"covar\" in key_b.lower() or \"hessian\" in key_b.lower():\n",
    "        B = V.transpose(-2, -1) @ B @ V\n",
    "        \n",
    "    diag_a, diag_b = extract_diagonals(A, B, slice_range)\n",
    "    \n",
    "    da = diag_a.detach().cpu().numpy()\n",
    "    db = diag_b.detach().cpu().numpy()\n",
    "    mask = (da > 0) & (db > 0)\n",
    "    \n",
    "    if mask.sum() < 5:\n",
    "        ax.text(0.5, 0.5, \"Invalid Data\", ha='center', va='center')\n",
    "        return\n",
    "        \n",
    "    raw_log_a = np.log10(da[mask])\n",
    "    raw_log_b = np.log10(db[mask])\n",
    "    \n",
    "    x_data = raw_log_b - raw_log_b.mean()\n",
    "    y_data = raw_log_a - raw_log_a.mean()\n",
    "    \n",
    "    slope, intercept, r2 = compute_loglog_fit_simple(x_data, y_data)\n",
    "    \n",
    "    ax.scatter(x_data, y_data, alpha=0.3, s=6, c='#1f77b4', edgecolors='none', rasterized=True)\n",
    "    \n",
    "    max_val = max(np.max(np.abs(x_data)), np.max(np.abs(y_data)))\n",
    "    limit = max_val * 1.2\n",
    "    x_ref = np.array([-limit, limit])\n",
    "    \n",
    "    ax.plot(x_ref, 1.0 * x_ref, color='#d62728', linestyle='--', lw=1.2, alpha=0.8, label='Slope=1')\n",
    "    ax.plot(x_ref, 2.0 * x_ref, color='#2ca02c', linestyle='-.', lw=1.2, alpha=0.8, label='Slope=2')\n",
    "    \n",
    "    y_fit = slope * x_ref + intercept\n",
    "    ax.plot(x_ref, y_fit, 'k-', lw=1.0, alpha=0.7, label='Fit')\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([-limit, limit])\n",
    "    ax.set_ylim([-limit, limit])\n",
    "    \n",
    "    clean_a = clean_tex_label(key_a)\n",
    "    clean_b = clean_tex_label(key_b)\n",
    "    \n",
    "    title_str = fr\"$\\mathbf{{{clean_a}}}$ vs $\\mathbf{{{clean_b}}}$\"\n",
    "    ax.set_title(title_str, fontsize=10)\n",
    "    \n",
    "    info_text = f\"$\\\\alpha = {slope:.2f}$\\n$R^2 = {r2:.2f}$\"\n",
    "    ax.text(0.05, 0.95, info_text, transform=ax.transAxes, \n",
    "            fontsize=9, verticalalignment='top', \n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.9))\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.axhline(0, color='gray', linewidth=0.5, alpha=0.3)\n",
    "    ax.axvline(0, color='gray', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "def plot_all_scatters_in_grid(epoch, base_path1, base_path2, slice_range, pair_list, config):\n",
    "    print(f\"Processing Epoch {epoch} for Centered Grid Plot...\")\n",
    "    \n",
    "    data = load_and_merge_data(epoch, base_path1, base_path2)\n",
    "    if data is None: return\n",
    "\n",
    "\n",
    "    H = torch.tensor(data[\"Hessian\"]).float()\n",
    "    if not torch.isfinite(H).all():\n",
    "            H = torch.nan_to_num(H)\n",
    "    hessian_eig = torch.linalg.eigh(H)\n",
    "    # else:\n",
    "    #     # Fallback\n",
    "    #     first_key = list(data.keys())[0]\n",
    "    #     dim = data[first_key].shape[0]\n",
    "    #     hessian_eig = (torch.ones(dim), torch.eye(dim))\n",
    "\n",
    "    n_plots = len(pair_list)\n",
    "    cols = 4 \n",
    "    rows = math.ceil(n_plots / cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3.5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, pair in enumerate(pair_list):\n",
    "        _plot_scatter_on_ax(axes[i], data, hessian_eig, pair, slice_range)\n",
    "        \n",
    "        row_idx = i // cols\n",
    "        col_idx = i % cols\n",
    "        if row_idx == rows - 1:\n",
    "            axes[i].set_xlabel(r\"Centered $\\log_{10}(X_{ii})$\")\n",
    "        if col_idx == 0:\n",
    "            axes[i].set_ylabel(r\"Centered $\\log_{10}(Y_{ii})$\")\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    fig.legend(by_label.values(), by_label.keys(), loc='upper center', \n",
    "               bbox_to_anchor=(0.5, 1.01), ncol=4, frameon=False, fontsize=11)\n",
    "\n",
    "    fig.suptitle(f\"Centered Log-Log Analysis @ Epoch {epoch}\", fontsize=16, y=1.03)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Centered_LogLog.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf',         \n",
    "        bbox_inches='tight',   \n",
    "        pad_inches=0.05,       \n",
    "        dpi=300                \n",
    "    )    \n",
    "    # plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved Grid Plot to {save_path}\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    del data, hessian_eig\n",
    "\n",
    "\n",
    "def analyze_epochs(epoch_list, base_path1, base_path2, slice_range, var_pairs):\n",
    "    results = {name: [] for name in var_pairs.keys()}\n",
    "    print(\"Starting Slope vs Epoch Analysis...\")\n",
    "    \n",
    "    for epoch in epoch_list:\n",
    "        data = load_and_merge_data(epoch, base_path1, base_path2)\n",
    "        if data is None: continue\n",
    "\n",
    "        if \"Hessian\" in data:\n",
    "            try:\n",
    "                L, V = torch.linalg.eigh(torch.tensor(data[\"Hessian\"]).float())\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for name, (key_a, key_b) in var_pairs.items():\n",
    "            if key_a not in data or key_b not in data: continue\n",
    "            \n",
    "            A = torch.tensor(data[key_a])\n",
    "            B = torch.tensor(data[key_b])\n",
    "            \n",
    "            if \"covar\" in key_a.lower() or \"hessian\" in key_a.lower(): A = V.transpose(-2, -1) @ A @ V\n",
    "            if \"covar\" in key_b.lower() or \"hessian\" in key_b.lower(): B = V.transpose(-2, -1) @ B @ V\n",
    "\n",
    "            diag_a, diag_b = extract_diagonals(A, B, slice_range)\n",
    "            \n",
    "            da = diag_a.detach().cpu().numpy()\n",
    "            db = diag_b.detach().cpu().numpy()\n",
    "            mask = (da > 0) & (db > 0)\n",
    "            if mask.sum() > 5:\n",
    "                log_a, log_b = np.log10(da[mask]), np.log10(db[mask])\n",
    "                slope, _, r_val, _, _ = stats.linregress(log_b, log_a)\n",
    "                results[name].append((epoch, slope, r_val**2))\n",
    "                \n",
    "        del data, L, V, A, B\n",
    "    return results\n",
    "\n",
    "def plot_slope_vs_epoch_multi(results, config):\n",
    "    if not any(results.values()):\n",
    "        print(\"No slope data to plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = cm.get_cmap('tab10')\n",
    "    \n",
    "    for i, (name, data) in enumerate(results.items()):\n",
    "        if not data: continue\n",
    "        data = sorted(data, key=lambda x: x[0])\n",
    "        epochs = [x[0] for x in data]\n",
    "        slopes = [x[1] for x in data]\n",
    "        plt.plot(epochs, slopes, marker='o', markersize=5, linewidth=2, \n",
    "                 label=name, color=colors(i), alpha=0.8)\n",
    "    \n",
    "    plt.axhline(y=1, color='gray', linestyle='--', linewidth=1.5, alpha=0.6, label=\"Slope=1\")\n",
    "    plt.axhline(y=2, color='gray', linestyle=':', linewidth=1.5, alpha=0.6, label=\"Slope=2\")\n",
    "    \n",
    "    plt.title(\"Evolution of Power-Law Exponent (Slope) over Training\")\n",
    "    plt.xlabel(\"Training Epoch\")\n",
    "    plt.ylabel(r\"Slope $\\alpha$\")\n",
    "    plt.ylim([0.5, 2.5])\n",
    "    plt.legend(loc='center right', bbox_to_anchor=(1.15, 0.5), frameon=True)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    apply_icml_style()\n",
    "\n",
    "    epoch_list = [1, 10, 30, 50, 70, 80, 90, 100]\n",
    "    slice_range = torch.arange(0, 1500)\n",
    "    Net_size =50\n",
    "    train_size = 2000\n",
    "    config = {'B': 128, 'alpha': 0.1, 'lss_fn': 'cse', 'model': 'CNN', 'dataset': 'cifar10'}\n",
    "    n_class = 10\n",
    "    # save_dir = f\"./AWCH_data/NS{Net_size}_TrainSize{train_size}_SampleN{20}_ClassN{n_class}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "    save_dir = f\"./AWCH_data/TrainSize{train_size}_SampleN{20}_ClassN{n_class}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "\n",
    "    base_path1 = os.path.join(save_dir, \"C_epoch_\")\n",
    "    base_path2 = os.path.join(save_dir, \"C_epoch_\") \n",
    "\n",
    "\n",
    "    var_pairs_for_evolution = {\n",
    "        \"C vs Hessian\": (\"C\", \"Hessian\"),\n",
    "        \"C1 vs Hessian\": (\"C1\", \"Hessian\"),\n",
    "        \"Covar vs Hessian\": (\"Covar\", \"Hessian\"),\n",
    "        \"H_2_d vs Hessian\": (\"H_2_d\", \"Hessian\"),\n",
    "    }\n",
    "    \n",
    "    results = analyze_epochs(epoch_list, base_path1, base_path2, slice_range, var_pairs_for_evolution)\n",
    "    plot_slope_vs_epoch_multi(results, config)\n",
    "\n",
    "    pairs_to_plot_grid = [\n",
    "        (\"C\", \"Hessian\"),\n",
    "        (\"C1\", \"Hessian\"),\n",
    "        (\"C1_dia\", \"Hessian\"),\n",
    "        (\"C1_dia_w_dia\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Hessian\"),\n",
    "        (\"Covar\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Covar\"),\n",
    "        (\"C\", \"Covar\"),\n",
    "        (\"C\", \"C1\"),\n",
    "        (\"C1\", \"C1_dia\"),\n",
    "        (\"C1_dia\", \"C1_dia_w_dia\"),\n",
    "        (\"H_2_d\", \"C1_dia_w_dia\")\n",
    "    ]\n",
    "    \n",
    "    target_epoch = 100\n",
    "    plot_all_scatters_in_grid(target_epoch, base_path1, base_path2, slice_range, pairs_to_plot_grid, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "\n",
    "def set_publication_style():\n",
    "    \"\"\"ÈÖçÁΩÆ Matplotlib ‰ª•Á¨¶Âêà ICML/NeurIPS ËÆ∫ÊñáÊ†áÂáÜ\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',          \n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',      \n",
    "        'font.size': 20,                \n",
    "        'axes.labelsize': 20,            \n",
    "        'axes.titlesize': 22,           \n",
    "        'xtick.labelsize': 20,           \n",
    "        'ytick.labelsize': 20,          \n",
    "        'legend.fontsize': 12,          \n",
    "        'figure.dpi': 300,              \n",
    "        'savefig.dpi': 300,            \n",
    "        'axes.linewidth': 2,          \n",
    "        'lines.linewidth': 2,            \n",
    "        'xtick.major.width': 2,     \n",
    "        'ytick.major.width': 2,\n",
    "        'xtick.direction': 'in',         \n",
    "        'ytick.direction': 'in',\n",
    "    })\n",
    "set_publication_style()\n",
    "\n",
    "\n",
    "def clean_tex_label(text):\n",
    "\n",
    "    return text.replace(\"_\", r\"\\_\")\n",
    "\n",
    "def compute_loglog_fit_simple(x, y):\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "    return slope, intercept, r_value**2\n",
    "\n",
    "def extract_diagonals(A, B, slice_range=None):\n",
    "    if slice_range is None:\n",
    "        slice_range = torch.arange(min(A.shape[0], B.shape[0]))\n",
    "    A = torch.flip(A, dims=[0, 1])\n",
    "    B = torch.flip(B, dims=[0, 1])\n",
    "    diag_a_val = torch.diag(A)[slice_range]\n",
    "    diag_b_val = torch.diag(B)[slice_range]\n",
    "    return diag_a_val, diag_b_val\n",
    "\n",
    "def load_and_merge_data(epoch, base_path1, base_path2):\n",
    "    file_path1 = f\"{base_path1}{epoch}.pt\"\n",
    "    file_path2 = f\"{base_path2}{epoch}.pt\"\n",
    "    if not os.path.exists(file_path1) or not os.path.exists(file_path2): return None\n",
    "    try:\n",
    "        d1 = torch.load(file_path1, map_location='cpu') if os.path.exists(file_path1) else {}\n",
    "        d2 = torch.load(file_path2, map_location='cpu') if os.path.exists(file_path2) else {}\n",
    "        return {**d1, **d2}\n",
    "    except: return None\n",
    "\n",
    "\n",
    "\n",
    "def _plot_scatter_on_ax(ax, data_dict, hessian_eig, var_pair, slice_range):\n",
    "\n",
    "    key_a, key_b = var_pair\n",
    "    \n",
    "    if key_a not in data_dict or key_b not in data_dict:\n",
    "        ax.text(0.5, 0.5, \"Missing Data\", ha='center', va='center')\n",
    "        return\n",
    "\n",
    "    A = torch.tensor(data_dict[key_a]).float()\n",
    "    B = torch.tensor(data_dict[key_b]).float()\n",
    "    \n",
    "    L, V = hessian_eig\n",
    "    if \"covar\" in key_a.lower() or \"hessian\" in key_a.lower():\n",
    "        A = V.transpose(-2, -1) @ A @ V\n",
    "    if \"covar\" in key_b.lower() or \"hessian\" in key_b.lower():\n",
    "        B = V.transpose(-2, -1) @ B @ V\n",
    "        \n",
    "    diag_a, diag_b = extract_diagonals(A, B, slice_range)\n",
    "    \n",
    "    da = diag_a.detach().cpu().numpy()\n",
    "    db = diag_b.detach().cpu().numpy()\n",
    "    mask = (da > 0) & (db > 0)\n",
    "    \n",
    "    if mask.sum() < 5:\n",
    "        ax.text(0.5, 0.5, \"Invalid Data\", ha='center', va='center')\n",
    "        return\n",
    "        \n",
    "    raw_log_a = np.log10(da[mask])\n",
    "    raw_log_b = np.log10(db[mask])\n",
    "    \n",
    "    x_data = raw_log_b - raw_log_b.mean()\n",
    "    y_data = raw_log_a - raw_log_a.mean()\n",
    "    \n",
    "    slope, intercept, r2 = compute_loglog_fit_simple(x_data, y_data)\n",
    "    \n",
    "\n",
    "    ax.scatter(x_data, y_data, alpha=0.5, s=15, c='#1f77b4', edgecolors='none', rasterized=True)\n",
    "    \n",
    "    max_val = max(np.max(np.abs(x_data)), np.max(np.abs(y_data)))\n",
    "    limit = max_val * 1.3 #\n",
    "    x_ref = np.array([-limit, limit])\n",
    "    \n",
    "    ax.plot(x_ref, 1.0 * x_ref, color='#d62728', linestyle='--', lw=2.5, alpha=0.9, label='Slope=1')\n",
    "    ax.plot(x_ref, 2.0 * x_ref, color='#2ca02c', linestyle='-.', lw=2.5, alpha=0.9, label='Slope=2')\n",
    "    \n",
    "    # 3. \n",
    "    y_fit = slope * x_ref + intercept\n",
    "    ax.plot(x_ref, y_fit, 'k-', lw=2.0, alpha=0.8, label='Fit')\n",
    "\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([-limit, limit])\n",
    "    ax.set_ylim([-limit, limit])\n",
    "    if \"C\" == key_a:\n",
    "        aname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "    elif \"Covar\" == key_a:\n",
    "        aname = \"$\\\\mathbf{Covar}$\"\n",
    "    elif \"H_2_d\" == key_a:\n",
    "        aname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "    elif \"C1\" == key_a:\n",
    "        aname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "    elif \"C1_dia\" ==   key_a:\n",
    "        aname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "    elif \"C1_dia_w_dia\" == key_a:\n",
    "        aname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "    elif \"H2\" == key_a:\n",
    "        aname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "    elif \"C2\" == key_a:\n",
    "        aname = \"$\\\\mathbf{C}^{hg}$\"\n",
    "    elif \"C3\" == key_a:\n",
    "        aname = \"$\\\\mathbf{C}^{gg}$\" \n",
    "    if \"C\" == key_b:\n",
    "        bname = \"$\\\\mathbf{C}_{AWD,raw}$\"\n",
    "    elif \"Covar\" == key_b:\n",
    "        bname = \"$\\\\mathbf{Covar}$\"\n",
    "    elif \"C1\" == key_b:\n",
    "        bname = \"$\\\\mathbf{C}^{hh}$\"\n",
    "    elif \"C1_dia\" ==   key_b:\n",
    "        bname = \"$\\\\mathbf{C}^{hh,SD}$\"\n",
    "    elif \"C1_dia_w_dia\" == key_b:\n",
    "        bname = \"$\\\\mathbf{C}^{hh,SD,WD}$\"\n",
    "    elif \"H2\" == key_b:\n",
    "        bname = \"$2\\\\mathbf{C}/\\\\sigma_w^2$\"\n",
    "    elif \"C2\" == key_b:\n",
    "        bname = \"$\\\\mathbf{C}^{hg}$\"\n",
    "    elif \"C3\" == key_b:\n",
    "        bname = \"$\\\\mathbf{C}^{gg}$\" \n",
    "    elif \"Hessian\" == key_b:\n",
    "        bname = \"$\\\\mathbf{H}$\"\n",
    "    title_str = fr\"{aname} vs {bname}\"\n",
    "    ax.set_title(title_str, fontsize=30, pad=10)\n",
    "    \n",
    "    info_text = f\"$\\\\alpha = {slope:.2f}$\\n$R^2 = {r2:.2f}$\"\n",
    "    ax.text(0.05, 0.95, info_text, transform=ax.transAxes, \n",
    "            fontsize=30, verticalalignment='top', fontweight='bold',\n",
    "            bbox=dict(boxstyle=\"square,pad=0.4\", fc=\"white\", ec=\"black\", lw=1.5, alpha=0.9))\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.0) \n",
    "        spine.set_color('black')\n",
    "\n",
    "\n",
    "    ax.axhline(0, color='gray', linewidth=1.0, alpha=0.4)\n",
    "    ax.axvline(0, color='gray', linewidth=1.0, alpha=0.4)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=30, width=2, length=6, direction='in')\n",
    "\n",
    "\n",
    "def plot_all_scatters_in_grid(epoch, base_path1, base_path2, slice_range, pair_list, config):\n",
    "\n",
    "    \n",
    "    print(f\"Processing Epoch {epoch} for Centered Grid Plot...\")\n",
    "    \n",
    "    data = load_and_merge_data(epoch, base_path1, base_path2)\n",
    "    if data is None: \n",
    "        print(\"Data not found.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    H = torch.tensor(data[\"Hessian\"]).float()\n",
    "    if not torch.isfinite(H).all(): H = torch.nan_to_num(H)\n",
    "    hessian_eig = torch.linalg.eigh(H)\n",
    "\n",
    "    n_plots = len(pair_list)\n",
    "    cols = 4 \n",
    "    rows = math.ceil(n_plots / cols)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(24, 6 * rows), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, pair in enumerate(pair_list):\n",
    "        _plot_scatter_on_ax(axes[i], data, hessian_eig, pair, slice_range)\n",
    "        \n",
    "        row_idx = i // cols\n",
    "        col_idx = i % cols\n",
    "        \n",
    "        if row_idx == rows - 1:\n",
    "            axes[i].set_xlabel(r\"Centered $\\log_{10}(X_{ii})$\", fontsize=30)\n",
    "        \n",
    "        if col_idx == 0:\n",
    "            axes[i].set_ylabel(r\"Centered $\\log_{10}(Y_{ii})$\", fontsize=30)\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    \n",
    "\n",
    "    fig.legend(by_label.values(), by_label.keys(), \n",
    "               loc='upper center', \n",
    "               bbox_to_anchor=(0.5, 1.05), \n",
    "               ncol=4, \n",
    "               frameon=True, \n",
    "               edgecolor='black',\n",
    "               fancybox=False, \n",
    "               fontsize=18,    \n",
    "               borderpad=0.8)\n",
    "\n",
    "    # fig.suptitle(f\"Appendix: Centered Log-Log Analysis (Epoch {epoch})\", fontsize=24, fontweight='bold', y=1.05)\n",
    "    \n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Appendix_Grid_Boxed.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    print(f\"Saving high-res boxed figure to {save_path}...\")\n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf', \n",
    "        bbox_inches='tight', \n",
    "        pad_inches=0.1, \n",
    "        dpi=300\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    del data, hessian_eig\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epoch_list = [100] \n",
    "    slice_range = torch.arange(0, 1500)\n",
    "    \n",
    "\n",
    "    train_size = 2000\n",
    "    config = {'B': 50, 'alpha': 0.1, 'lss_fn': 'mse', 'model': 'FC', 'dataset': 'mnist'}\n",
    "    n_class = 10\n",
    "\n",
    "    save_dir = f\"./AWCH_data/TrainSize{train_size}_SampleN{20}_ClassN{n_class}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "    base_path1 = os.path.join(save_dir, \"C_epoch_\")\n",
    "    base_path2 = os.path.join(save_dir, \"C_epoch_\") \n",
    "\n",
    "    pairs_to_plot_grid = [\n",
    "        (\"C\", \"Hessian\"),\n",
    "        (\"C1\", \"Hessian\"),\n",
    "        (\"C1_dia\", \"Hessian\"),\n",
    "        (\"C1_dia_w_dia\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Hessian\"),\n",
    "        (\"Covar\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Covar\"),\n",
    "        (\"C\", \"Covar\"),\n",
    "        (\"C\", \"C1\"),\n",
    "        (\"C1\", \"C1_dia\"),\n",
    "        (\"C1_dia\", \"C1_dia_w_dia\"),\n",
    "        (\"H_2_d\", \"C1_dia_w_dia\")\n",
    "    ]\n",
    "    \n",
    "    plot_all_scatters_in_grid(100, base_path1, base_path2, slice_range, pairs_to_plot_grid, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c80e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import run\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "def apply_icml_appendix_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',\n",
    "        'font.size': 16,            \n",
    "        'axes.labelsize': 18,\n",
    "        'axes.titlesize': 18,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14,\n",
    "        'legend.fontsize': 14,\n",
    "        'lines.linewidth': 2.0,    \n",
    "        'axes.linewidth': 1.5,      \n",
    "        'figure.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "    })\n",
    "\n",
    "\n",
    "def clean_tex_label(text):\n",
    "    return text.replace(\"_\", r\"\\_\")\n",
    "\n",
    "def compute_loglog_fit_simple(x, y):\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "    return slope, intercept, r_value**2\n",
    "\n",
    "def extract_diagonals(A, B, slice_range=None):\n",
    "    if slice_range is None:\n",
    "        slice_range = torch.arange(min(A.shape[0], B.shape[0]))\n",
    "    A = torch.flip(A, dims=[0, 1])\n",
    "    B = torch.flip(B, dims=[0, 1])\n",
    "    diag_a_val = torch.diag(A)[slice_range]\n",
    "    diag_b_val = torch.diag(B)[slice_range]\n",
    "    return diag_a_val, diag_b_val\n",
    "\n",
    "def load_and_merge_data(epoch, base_path1, base_path2, run_idx=0):\n",
    "    file_path1 = f\"{base_path1}{epoch}_run_{run_idx}.pt\"\n",
    "    file_path2 = f\"{base_path2}{epoch}_run_{run_idx}.pt\"\n",
    "    if not os.path.exists(file_path1) or not os.path.exists(file_path2): return None\n",
    "    try:\n",
    "        d1 = torch.load(file_path1, map_location='cpu') if os.path.exists(file_path1) else {}\n",
    "        d2 = torch.load(file_path2, map_location='cpu') if os.path.exists(file_path2) else {}\n",
    "        return {**d1, **d2}\n",
    "    except: return None\n",
    "\n",
    "\n",
    "\n",
    "def _plot_scatter_on_ax(ax, data_dict, hessian_eig, var_pair, slice_range):\n",
    "\n",
    "    key_a, key_b = var_pair\n",
    "    \n",
    "\n",
    "    if key_a not in data_dict or key_b not in data_dict:\n",
    "        ax.text(0.5, 0.5, \"Missing Data\", ha='center', va='center')\n",
    "        return\n",
    "\n",
    "    A = torch.tensor(data_dict[key_a]).float()\n",
    "    B = torch.tensor(data_dict[key_b]).float()\n",
    "    \n",
    "    L, V = hessian_eig\n",
    "    if \"covar\" in key_a.lower() or \"hessian\" in key_a.lower():\n",
    "        A = V.transpose(-2, -1) @ A @ V\n",
    "    if \"covar\" in key_b.lower() or \"hessian\" in key_b.lower():\n",
    "        B = V.transpose(-2, -1) @ B @ V\n",
    "        \n",
    "    diag_a, diag_b = extract_diagonals(A, B, slice_range)\n",
    "    \n",
    "    da = diag_a.detach().cpu().numpy()\n",
    "    db = diag_b.detach().cpu().numpy()\n",
    "    mask = (da > 0) & (db > 0)\n",
    "    \n",
    "    if mask.sum() < 5:\n",
    "        ax.text(0.5, 0.5, \"Invalid Data\", ha='center', va='center')\n",
    "        return\n",
    "        \n",
    "    raw_log_a = np.log10(da[mask])\n",
    "    raw_log_b = np.log10(db[mask])\n",
    "    \n",
    "    x_data = raw_log_b - raw_log_b.mean()\n",
    "    y_data = raw_log_a - raw_log_a.mean()\n",
    "    \n",
    "    slope, intercept, r2 = compute_loglog_fit_simple(x_data, y_data)\n",
    "\n",
    "    ax.scatter(x_data, y_data, alpha=0.5, s=15, c='#1f77b4', edgecolors='none', rasterized=True)\n",
    "    \n",
    "    max_val = max(np.max(np.abs(x_data)), np.max(np.abs(y_data)))\n",
    "    limit = max_val * 1.3 \n",
    "    x_ref = np.array([-limit, limit])\n",
    "    \n",
    "\n",
    "    ax.plot(x_ref, 1.0 * x_ref, color='#d62728', linestyle='--', lw=2.5, alpha=0.9, label='Slope=1')\n",
    "    ax.plot(x_ref, 2.0 * x_ref, color='#2ca02c', linestyle='-.', lw=2.5, alpha=0.9, label='Slope=2')\n",
    "    \n",
    "\n",
    "    y_fit = slope * x_ref + intercept\n",
    "    ax.plot(x_ref, y_fit, 'k-', lw=2.0, alpha=0.8, label='Fit')\n",
    "\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([-limit, limit])\n",
    "    ax.set_ylim([-limit, limit])\n",
    "    \n",
    "\n",
    "    clean_a = clean_tex_label(key_a)\n",
    "    clean_b = clean_tex_label(key_b)\n",
    "    title_str = fr\"$\\mathbf{{{clean_a}}}$ vs $\\mathbf{{{clean_b}}}$\"\n",
    "    ax.set_title(title_str, fontsize=16, pad=10) \n",
    "    \n",
    "    info_text = f\"$\\\\alpha = {slope:.2f}$\\n$R^2 = {r2:.2f}$\"\n",
    "    ax.text(0.05, 0.95, info_text, transform=ax.transAxes, \n",
    "            fontsize=14, verticalalignment='top', fontweight='bold',\n",
    "            bbox=dict(boxstyle=\"square,pad=0.4\", fc=\"white\", ec=\"black\", lw=1.5, alpha=0.9))\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.0) \n",
    "        spine.set_color('black')\n",
    "\n",
    "\n",
    "    ax.axhline(0, color='gray', linewidth=1.0, alpha=0.4)\n",
    "    ax.axvline(0, color='gray', linewidth=1.0, alpha=0.4)\n",
    "    \n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12, width=1.5, length=5, direction='in')\n",
    "\n",
    "\n",
    "def plot_all_scatters_in_grid(epoch, base_path1, base_path2, slice_range, pair_list, config, run_idx=0):\n",
    "\n",
    "    apply_icml_appendix_style() \n",
    "    \n",
    "    print(f\"Processing Epoch {epoch} for Centered Grid Plot...\")\n",
    "    \n",
    "    data = load_and_merge_data(epoch, base_path1, base_path2, run_idx=run_idx)\n",
    "    if data is None: \n",
    "        print(\"Data not found.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    H = torch.tensor(data[\"Hessian\"]).float()\n",
    "    if not torch.isfinite(H).all(): H = torch.nan_to_num(H)\n",
    "    hessian_eig = torch.linalg.eigh(H)\n",
    "\n",
    "\n",
    "    n_plots = len(pair_list)\n",
    "    cols = 4 \n",
    "    rows = math.ceil(n_plots / cols)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(24, 6 * rows), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, pair in enumerate(pair_list):\n",
    "        _plot_scatter_on_ax(axes[i], data, hessian_eig, pair, slice_range)\n",
    "        \n",
    "\n",
    "        row_idx = i // cols\n",
    "        col_idx = i % cols\n",
    "\n",
    "        if row_idx == rows - 1:\n",
    "            axes[i].set_xlabel(r\"Centered $\\log_{10}(X_{ii})$\", fontsize=16)\n",
    "        \n",
    "\n",
    "        if col_idx == 0:\n",
    "            axes[i].set_ylabel(r\"Centered $\\log_{10}(Y_{ii})$\", fontsize=16)\n",
    "\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    \n",
    "    fig.legend(by_label.values(), by_label.keys(), \n",
    "               loc='upper center', \n",
    "               bbox_to_anchor=(0.5, 1.02), \n",
    "               ncol=4, \n",
    "               frameon=True,\n",
    "               edgecolor='black',\n",
    "               fancybox=False, \n",
    "               fontsize=18,    \n",
    "               borderpad=0.8)\n",
    "\n",
    "    fig.suptitle(f\"Appendix: Centered Log-Log Analysis (Epoch {epoch})\", fontsize=24, fontweight='bold', y=1.05)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    del data, hessian_eig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    slice_range = torch.arange(0, 1000)\n",
    "    net_size = 1000\n",
    "    n_class = 10\n",
    "    train_size = 2000\n",
    "    config = {'B':100, 'alpha': 0.1, 'lss_fn': 'cse', 'model': 'MLP', 'dataset': 'cifar10'}\n",
    "    run_idx = 4\n",
    "    sample_number = 20\n",
    "\n",
    "    # \n",
    "    save_dir = f\"./AWCH_data/NS{net_size}_TrainSize{train_size}_SampleN{sample_number}_ClassN{n_class}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}\"\n",
    "\n",
    "    base_path1 = os.path.join(save_dir, \"C_epoch_\")\n",
    "    base_path2 = os.path.join(save_dir, \"C_epoch_\") \n",
    "\n",
    "    pairs_to_plot_grid = [\n",
    "        (\"C\", \"Hessian\"),\n",
    "        (\"C1\", \"Hessian\"),\n",
    "        (\"C1_dia\", \"Hessian\"),\n",
    "        (\"C1_dia_w_dia\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Hessian\"),\n",
    "        (\"Covar\", \"Hessian\"),\n",
    "        (\"H_2_d\", \"Covar\"),\n",
    "        (\"C\", \"Covar\"),\n",
    "        (\"C\", \"C1\"),\n",
    "        (\"C1\", \"C1_dia\"),\n",
    "        (\"C1_dia\", \"C1_dia_w_dia\"),\n",
    "        (\"H_2_d\", \"C1_dia_w_dia\")\n",
    "    ]\n",
    "    \n",
    "    plot_all_scatters_in_grid(150, base_path1, base_path2, slice_range, pairs_to_plot_grid, config, run_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa7ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
