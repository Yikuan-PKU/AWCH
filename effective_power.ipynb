{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9321bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_config\n",
    "import torch\n",
    "import os\n",
    "\n",
    "max_e = 150 #####  task idxs\n",
    "sample_number = 20    ## number of samples used to compute AWCH\n",
    "train_size =2000 ## number of training samples per class\n",
    "\n",
    "config = model_config.set_config('none',test_size = 1000, train_size = train_size, max_epoch=max_e)\n",
    "config['add_regulization'] = False\n",
    "config['beta'] = 10\n",
    "config['lss_fn'] = 'cse'\n",
    "config['dataset'] = 'cifar10'  # 'mnist'  #'cifar10'  \n",
    "config['model'] = 'MLP' # 'CNN'  #'FC' #'CNN' \n",
    "config['sample_holder'] = [0,1,2,3,4,5,6,7,8,9]  ## the samples used to compute AWCH\n",
    "config['class_number'] = 10\n",
    "config['B'] = 100 # 30\n",
    "config['alpha'] = 0.1 # 0.5\n",
    "net_size = 1000  \n",
    "\n",
    "loss_fn = config['lss_fn']\n",
    "sample_num  = config['train_size']\n",
    "sample_holder = config['sample_holder']\n",
    "mis_label_prob = config['rho']\n",
    "\n",
    "batch_size = config['B']\n",
    "# config['sample_holder'] = []\n",
    "# config['class_number'] = \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "load_path = f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}/h_g_tensors_holder_epoch_{config['max_epoch']}.pt\"\n",
    "load_path = f\"./AWCH_data/NS{net_size}_TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}/h_g_tensors_holder_epoch_{config['max_epoch']}.pt\"\n",
    "print(f\"Loading data from: {load_path}\")\n",
    "loaded_data = torch.load(load_path,weights_only=False)\n",
    "h_holder= loaded_data['h_holder']\n",
    "g_holder= loaded_data['g_holder']\n",
    "components= loaded_data['components']\n",
    "Covar = loaded_data['Covar']\n",
    "Hessian = loaded_data['matrix']\n",
    "del loaded_data\n",
    "components = torch.tensor(components).to(device)\n",
    "h_holder = torch.tensor(h_holder).to(device)\n",
    "h_holder = components @ h_holder @ components.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei'] \n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "\n",
    "def analyze_eigen_structure(h_data, metric_mode='ipr', smoothing_window=50):\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    ax_spec = axes[0]\n",
    "    ax_struct = axes[1]\n",
    "    \n",
    "    if isinstance(h_data[0], torch.Tensor):\n",
    "        H_DIM = h_data[0].shape[0]\n",
    "    else:\n",
    "        H_DIM = h_data[0].shape[0]\n",
    "    \n",
    "    \n",
    "    total_samples = len(h_data)\n",
    "    num_classes = 10\n",
    "    samples_per_class = total_samples // num_classes\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        for sample_i in range(1): \n",
    "            global_idx = class_idx * samples_per_class + sample_i\n",
    "            if global_idx >= total_samples: break\n",
    "            \n",
    "            H = h_data[global_idx]\n",
    "            if isinstance(H, torch.Tensor):\n",
    "                H = H.cpu().numpy()\n",
    "            \n",
    "            if not np.isfinite(H).all():\n",
    "                H = np.nan_to_num(H, nan=0.0)\n",
    "            \n",
    "            try:\n",
    "                w, v = np.linalg.eigh(H)\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "                \n",
    "            idx_desc = np.argsort(w)[::-1]\n",
    "            w_desc = w[idx_desc]\n",
    "            v_desc = v[:, idx_desc] # (Dim, Rank)\n",
    "            \n",
    "            ranks = np.arange(1, len(w_desc) + 1)\n",
    "            \n",
    "\n",
    "            V_squared = v_desc ** 2\n",
    "            \n",
    "            if metric_mode == 'max_weight':\n",
    "                metric_vals = np.max(V_squared, axis=0)\n",
    "                ylabel = r'Max Squared Component ($\\max v_{ki}^2$)'\n",
    "                title_suffix = 'High Value = Localized'\n",
    "                \n",
    "            elif metric_mode == 'pr_normalized':\n",
    "                sum_sq = np.sum(V_squared, axis=0)\n",
    "                sum_quad = np.sum(V_squared ** 2, axis=0) \n",
    "                pr_values = (sum_sq ** 2) / sum_quad\n",
    "                metric_vals = pr_values / H_DIM\n",
    "                ylabel = r'Normalized Participation Ratio ($PR / N$)'\n",
    "                title_suffix = 'High Value (~1) = Delocalized'\n",
    "            \n",
    "            elif metric_mode == 'ipr':\n",
    "                metric_vals = np.sum(v_desc**4, axis=0) # IPR = sum(v^4)\n",
    "                ylabel = r'Inverse Participation Ratio ($\\sum v_{ki}^4$)'\n",
    "                title_suffix = 'High Value = Localized'\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"metric_mode must be 'max_weight', 'pr_normalized', or 'ipr'\")\n",
    "\n",
    "\n",
    "            label_txt = f'Class {class_idx}' if sample_i == 0 else None\n",
    "            \n",
    "            # Task 1: Spectrum\n",
    "            ax_spec.loglog(ranks, np.abs(w_desc), color=colors[class_idx], alpha=0.5, linewidth=1.5)\n",
    "            ax_spec.set_ylim(1e-20, 1e2)\n",
    "            # Task 2: Structure (Structure Plot)\n",
    "            ax_struct.loglog(ranks, metric_vals, color=colors[class_idx], \n",
    "                             alpha=0.15, marker='.', markersize=1, linestyle='None')\n",
    "            \n",
    "            if len(metric_vals) > smoothing_window:\n",
    "                kernel = np.ones(smoothing_window) / smoothing_window\n",
    "                ma = np.convolve(metric_vals, kernel, mode='valid')\n",
    "                ma_ranks = ranks[smoothing_window-1:]\n",
    "                ax_struct.loglog(ma_ranks, ma, color=colors[class_idx], alpha=0.8, linewidth=1.5, label=label_txt)\n",
    "\n",
    "    ax_spec.set_title('Task 1: Eigenvalue Spectrum', fontsize=14)\n",
    "    ax_spec.set_xlabel('Rank Index $i$', fontsize=12)\n",
    "    ax_spec.set_ylabel(r'Eigenvalue $|\\lambda_i|$', fontsize=12)\n",
    "    ax_spec.grid(True, which=\"both\", alpha=0.3)\n",
    "    \n",
    "    ax_struct.set_title(f'Task 2: Eigenvector Structure ({metric_mode.upper()})\\n{title_suffix}', fontsize=14)\n",
    "    ax_struct.set_xlabel('Rank Index $i$', fontsize=12)\n",
    "    ax_struct.set_ylabel(ylabel, fontsize=12)\n",
    "    ax_struct.grid(True, which=\"both\", alpha=0.3)\n",
    "    \n",
    "    ax_struct.legend(loc='best', fontsize=8, ncol=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "analyze_eigen_structure(h_holder, metric_mode='ipr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_icml_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'DejaVu Serif', 'serif'],\n",
    "        'font.size': 14,\n",
    "        'axes.labelsize': 15,\n",
    "        'axes.titlesize': 15,\n",
    "        'legend.fontsize': 12,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'lines.linewidth': 1.5,\n",
    "        'lines.markersize': 2,\n",
    "        'grid.alpha': 0.3,\n",
    "        'axes.grid': True,\n",
    "        'savefig.dpi': 300,\n",
    "        'figure.autolayout': True\n",
    "    })\n",
    "def get_top_k_decomposition(h_holder, k=800):\n",
    "    print(f\"1. Performing Eigen Decomposition (Full Rank)...\")\n",
    "    h_holder = h_holder.to(device)\n",
    "    vals, vecs = torch.linalg.eigh(h_holder)\n",
    "    vals = torch.flip(vals, dims=[1])\n",
    "    vecs = torch.flip(vecs, dims=[2])\n",
    "    N = vals.shape[1]\n",
    "    actual_k = min(k, N)\n",
    "    print(f\"2. Filtering Top {actual_k} modes...\")\n",
    "    vals_k = vals[:, :actual_k]\n",
    "    vecs_k = vecs[:, :, :actual_k]\n",
    "    del vals, vecs\n",
    "    torch.cuda.empty_cache()\n",
    "    return vals_k, vecs_k\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_H_C_only(eigenvalues, eigenvectors, chunk_size=16):\n",
    "\n",
    "    N_samples = eigenvalues.shape[0]\n",
    "    \n",
    "    N_dim = eigenvectors.shape[1] \n",
    "    H_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "    C_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, N_samples, chunk_size):\n",
    "            end_idx = min(i + chunk_size, N_samples)\n",
    "            \n",
    "            lam_chunk = eigenvalues[i:end_idx]   # (Chunk, N)\n",
    "            vec_chunk = eigenvectors[i:end_idx]  # (Chunk, N, N)\n",
    "\n",
    "            vec_chunk = torch.flip(vec_chunk, dims=[1]) \n",
    "            \n",
    "            V_sq_chunk = vec_chunk ** 2  # (Chunk, N, N)\n",
    "\n",
    "\n",
    "            \n",
    "            H_batch_chunk = torch.matmul(V_sq_chunk, lam_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "            \n",
    "            lam_sq_chunk = lam_chunk ** 2\n",
    "            C_batch_chunk = torch.matmul(V_sq_chunk, lam_sq_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            H_mean_accumulator += torch.sum(H_batch_chunk, dim=0).cpu().numpy()\n",
    "            C_mean_accumulator += torch.sum(C_batch_chunk, dim=0).cpu().numpy()\n",
    "            \n",
    "            del lam_chunk, vec_chunk, V_sq_chunk, H_batch_chunk, C_batch_chunk\n",
    "            \n",
    "    return H_mean_accumulator / N_samples, C_mean_accumulator / N_samples\n",
    "\n",
    "\n",
    "def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "    print(f\"Computing Gap Matrix (Batch Size={batch_size})...\")\n",
    "    B, N, num_modes = eigenvectors.shape \n",
    "    eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "    total_gap_sum = torch.zeros((N, num_modes), device=device)\n",
    "    with torch.no_grad():\n",
    "        for b_start in range(0, B, batch_size):\n",
    "            b_end = min(b_start + batch_size, B)\n",
    "            vec_chunk = eigenvectors[b_start:b_end] \n",
    "            val_chunk = eigenvalues[b_start:b_end]      \n",
    "            lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "            V_sq = vec_chunk ** 2\n",
    "            numerator = torch.cumsum(lam_sq * V_sq, dim=2) \n",
    "            total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "\n",
    "            denominator = total_energy \n",
    "            gap_chunk = numerator / denominator \n",
    "\n",
    "            total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "            del vec_chunk, val_chunk, lam_sq, V_sq, numerator, denominator, gap_chunk\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_gap_matrix = total_gap_sum / B\n",
    "    return avg_gap_matrix.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_artificial_spectra(N, mode='elbow', k=10 , alpha=1.5, k_target=800):\n",
    "    indices = torch.arange(1, k_target + 1, device=device).float()\n",
    "    if mode == 'elbow':\n",
    "        spectrum = 10 * indices **(-2)\n",
    "        spectrum[:k] = 0.1 \n",
    "    elif mode == 'smooth':\n",
    "        spectrum = indices ** (-alpha) * 1.0\n",
    "    return spectrum\n",
    "\n",
    "def create_gap_from_real_spectrum(eigenvalues, idx = 10):\n",
    "    gap_spectrum = eigenvalues.clone()\n",
    "    # gap_spectrum[:,0] = torch.mean(gap_spectrum[:,0], dim=0)\n",
    "    gap_spectrum[:, idx:] = gap_spectrum[:, idx:] * 1e-5\n",
    "    return gap_spectrum\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def reshape_the_real_spectrum(eigenvalues, n_fit=10, slope_factor=1.0, noise_std=1.0):\n",
    "\n",
    "    device = eigenvalues.device\n",
    "    smoothed = eigenvalues.clone()\n",
    "    B = eigenvalues.shape[0]\n",
    "    \n",
    "    target_ranks = torch.arange(1, n_fit + 1, device=device).float()\n",
    "    log_target_ranks = torch.log(target_ranks)\n",
    "    \n",
    "    vals_to_fit = eigenvalues[:, :n_fit]\n",
    "    log_vals = torch.log(vals_to_fit)\n",
    "    \n",
    "    log_ranks_mean = log_target_ranks.mean()\n",
    "    log_vals_mean = log_vals.mean(dim=1, keepdim=True) # [B, 1]\n",
    "    \n",
    "    X_centered = log_target_ranks - log_ranks_mean # [n_fit]\n",
    "    Y_centered = log_vals - log_vals_mean          # [B, n_fit]\n",
    "    \n",
    "    denom = (X_centered ** 2).sum()\n",
    "    numer = (Y_centered * X_centered.unsqueeze(0)).sum(dim=1, keepdim=True)\n",
    "    current_slope = numer / denom  # [B, 1]\n",
    "    \n",
    "    target_slope = current_slope * slope_factor\n",
    "    \n",
    "\n",
    "    bias_noise = 0.0\n",
    "    if noise_std > 0.0:\n",
    "        bias_noise = torch.randn(B, 1, device=device) * noise_std\n",
    "    \n",
    "\n",
    "    anchor_idx = n_fit - 1\n",
    "    log_rank_anchor = log_target_ranks[anchor_idx]\n",
    "    log_val_anchor = log_vals[:, anchor_idx].unsqueeze(1) # [B, 1]\n",
    "\n",
    "    log_predicted = log_val_anchor + target_slope * (log_target_ranks.unsqueeze(0) - log_rank_anchor) + bias_noise\n",
    "    \n",
    "    smoothed[:, :n_fit] = torch.exp(log_predicted)\n",
    "    \n",
    "    return smoothed\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "\n",
    "def plot_comparison_loglog(ax, data_orig, data_new, label_name, CH_slice):\n",
    "    \"\"\"\n",
    "    Helper function to plot log-log comparison between Original and New metric.\n",
    "    Visuals optimized for presentation.\n",
    "    \"\"\"\n",
    "    x = data_orig[CH_slice]\n",
    "    y = data_new[CH_slice]\n",
    "    \n",
    "    mask = (x > 0) & (y > 0)\n",
    "    x_clean, y_clean = x[mask], y[mask]\n",
    "\n",
    "    if len(x_clean) > 1:\n",
    "        log_x, log_y = np.log10(x_clean), np.log10(y_clean)\n",
    "        slope, intercept, r_val, _, _ = linregress(log_x, log_y)\n",
    "        \n",
    "        ax.scatter(x_clean, y_clean, s=30, alpha=0.6, color='royalblue', edgecolors='white', linewidth=0.5, label='Data Points')\n",
    "        \n",
    "        fit_y = 10**(intercept + slope * log_x)\n",
    "        ax.plot(x_clean, fit_y, color='firebrick', linestyle='-', linewidth=3.0, label=f'Fit: slope={slope:.2f}')\n",
    "        \n",
    "        min_val = min(x_clean.min(), y_clean.min())\n",
    "        max_val = max(x_clean.max(), y_clean.max())\n",
    "        ref_line = np.linspace(min_val, max_val, 100)\n",
    "        ax.plot(ref_line, ref_line, 'k--', linewidth=2.0, alpha=0.8, label='Ref: slope=1')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax.set_xlabel(f'Original {label_name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(f'Current {label_name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f'{label_name} Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    ax.legend(loc='best', fontsize=12, frameon=True, framealpha=0.9)\n",
    "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.4, color='gray') \n",
    "\n",
    "def analyze_slope_and_plot(CH_slice,H, C, gap_matrix, spectrum_data, title, \n",
    "                           H_ref, C_ref, \n",
    "                           ax_scatter, ax_gap, ax_spectrum, ax_comp_c, ax_comp_h,\n",
    "                           end_idx=800):\n",
    "    \n",
    "    # --- 1. C_ii vs H_ii Scatter Plot ---\n",
    "    x_data = H[CH_slice]\n",
    "    y_data = C[CH_slice]\n",
    "    mask = (x_data > 0) & (y_data > 0)\n",
    "    x_data, y_data = x_data[mask], y_data[mask]\n",
    "    \n",
    "    if len(x_data) > 1:\n",
    "        log_x, log_y = np.log10(x_data), np.log10(y_data)\n",
    "        slope, intercept, _, _, _ = linregress(log_x, log_y)\n",
    "        \n",
    "        ax_scatter.scatter(x_data, y_data, s=6, alpha=0.5, color='navy', label='Data Points')\n",
    "        \n",
    "        fit_line_y = 10**(intercept + slope * log_x)\n",
    "        ax_scatter.plot(x_data, fit_line_y, color='red', linestyle='-', linewidth=1, label=f'Slope = {slope:.2f}')\n",
    "        \n",
    "        # Reference lines\n",
    "        mid_x, mid_y = np.mean(log_x), np.mean(log_y)\n",
    "        ref_line_x = np.logspace(min(log_x), max(log_x), 100)\n",
    "        \n",
    "        ref_line_y1 = 10**(1.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y1, 'k--', linewidth=2.0, label='Slope=1')\n",
    "        \n",
    "        ref_line_y2 = 10**(2.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y2, color='darkgreen', linestyle=':', linewidth=2.5, label='Slope=2')\n",
    "    \n",
    "    ax_scatter.set_xscale('log')\n",
    "    ax_scatter.set_yscale('log')\n",
    "    ax_scatter.set_xlabel(r'$H_{ii}$', fontsize=14, fontweight='bold')\n",
    "    ax_scatter.set_ylabel(r'$C_{ii}$', fontsize=14, fontweight='bold')\n",
    "    ax_scatter.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax_scatter.legend(loc='upper left', fontsize=12)\n",
    "    ax_scatter.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "    \n",
    "    # --- 2. Gap Curve Plot ---\n",
    "    real_k = gap_matrix.shape[1]\n",
    "    k_values = np.arange(1, real_k + 1)\n",
    "    avg_gap_curve = np.mean(gap_matrix[:1500], axis=0)\n",
    "    # print(f\"Gap Matrix Shape: {gap_matrix.shape}\")\n",
    "    # print(avg_gap_curve)\n",
    "    indices_to_plot = [1, 10, 50, 100, 200, 400, 700, 1000, 1500]\n",
    "    colors_gap = plt.cm.viridis(np.linspace(0, 0.9, len(indices_to_plot))) \n",
    "    \n",
    "    for idx, color in zip(indices_to_plot, colors_gap):\n",
    "        if idx < gap_matrix.shape[0]:\n",
    "            ax_gap.semilogx(k_values, gap_matrix[idx, :], color=color, linewidth=2.0, alpha=0.8, label=f'i={idx+1}')\n",
    "            \n",
    "    ax_gap.semilogx(k_values, avg_gap_curve, 'k--', linewidth=3.5, alpha=1.0, label='Avg')\n",
    "    \n",
    "    ax_gap.legend(loc='upper right', fontsize=10, ncol=2) \n",
    "    ax_gap.set_title(f\"Gap Metric\", fontsize=16, fontweight='bold')\n",
    "    ax_gap.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "    ax_gap.set_xlabel('k (Cutoff)', fontsize=14)\n",
    "    ax_gap.set_ylabel('Cumulative contribution', fontsize=14)\n",
    "    ax_gap.set_ylim(1e-3, 1.05)\n",
    "    \n",
    "    # --- 3. Spectrum Plot (Sampled) ---\n",
    "    if isinstance(spectrum_data, torch.Tensor):\n",
    "        spec_np = spectrum_data.detach().cpu().numpy()\n",
    "    else:\n",
    "        spec_np = spectrum_data\n",
    "        \n",
    "    B_samples = spec_np.shape[0]\n",
    "    num_classes = 10\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, num_classes))\n",
    "    ranks = np.arange(1, spec_np.shape[1] + 1)\n",
    "    \n",
    "    if B_samples >= num_classes:\n",
    "        samples_per_class = B_samples // num_classes\n",
    "        selected_indices = [\n",
    "            i * samples_per_class+1\n",
    "            for i in range(num_classes)\n",
    "        ]\n",
    "    else:\n",
    "        selected_indices = range(B_samples)\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if idx < B_samples:\n",
    "            lbl = f\"class {i}\" \n",
    "            ax_spectrum.loglog(ranks, spec_np[idx], color=colors[i % num_classes], \n",
    "                               alpha=0.8, linewidth=2.5, label=lbl)\n",
    "            \n",
    "    ax_spectrum.axvline(x=10, color='dimgray', linestyle=':', linewidth=2.0, alpha=0.8, label='k=10')\n",
    "    \n",
    "    ax_spectrum.set_title('Eigenvalue Spectrum (Sampled)', fontsize=16, fontweight='bold')\n",
    "    ax_spectrum.set_xlabel('Rank', fontsize=14)\n",
    "    ax_spectrum.set_ylabel(r'$|\\lambda_i|$', fontsize=14)\n",
    "    ax_spectrum.grid(True, which=\"both\", alpha=0.3)\n",
    "    ax_spectrum.legend(loc='best', fontsize=10, ncol=2)\n",
    "\n",
    "    # --- 4. NEW: C_ii Comparison ---\n",
    "    plot_comparison_loglog(ax_comp_c, C_ref, C, r'$C_{ii}$', CH_slice)\n",
    "\n",
    "    # --- 5. NEW: H_ii Comparison ---\n",
    "    plot_comparison_loglog(ax_comp_h, H_ref, H, r'$H_{ii}$', CH_slice)\n",
    "###########################################################################################\n",
    "def main(CH_slice, h_holder_input=None, a1=1.0, a2=1.6, a3=3.0, k_target=800):\n",
    "    \n",
    "    h_holder = h_holder_input\n",
    "    B, N, _ = h_holder.shape\n",
    "    print(f\"Processing input data: B={B}, N={N}\")\n",
    "\n",
    "    # 1. Real Eigen Decomposition\n",
    "    torch.backends.cuda.preferred_linalg_library('magma')\n",
    "    real_eigenvalues_orig, eigenvectors = get_top_k_decomposition(h_holder, k=k_target)\n",
    "    \n",
    "    del h_holder \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # ==========================================\n",
    "    # A1. Real Data (Original) - Baseline\n",
    "    # ==========================================\n",
    "    print(\"\\n--- Processing Real Data (Original) ---\")\n",
    "    \n",
    "\n",
    "\n",
    "    H_r_orig, C_r_orig = compute_H_C_only(real_eigenvalues_orig, eigenvectors)\n",
    "    Gap_r_orig = compute_full_gap_matrix_efficient(real_eigenvalues_orig, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_orig, 'C': C_r_orig, 'Gap': Gap_r_orig, \n",
    "        'Spec': real_eigenvalues_orig, 'Title': \"Real Data (Original)\"\n",
    "    })\n",
    "\n",
    "    # ==========================================\n",
    "    # A2. Real Data (Smoothed / Modified)\n",
    "    # ==========================================\n",
    "    print(\"\\n--- Processing Real Data (Modified) ---\")\n",
    "    real_eigenvalues_smooth1 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=3)\n",
    "    # real_eigenvalues_smooth1[:,0] = torch.mean(real_eigenvalues_orig[:,0], dim=0)\n",
    "\n",
    "    \n",
    "    H_r_smooth1, C_r_smooth1 = compute_H_C_only(real_eigenvalues_smooth1, eigenvectors)\n",
    "    Gap_r_smooth1 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth1, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth1, 'C': C_r_smooth1, 'Gap': Gap_r_smooth1, \n",
    "        'Spec': real_eigenvalues_smooth1, 'Title': \"Real Data (Modified)\"\n",
    "    })\n",
    "    \n",
    "    print(\"\\n--- Processing Real Data (Modified) ---\")\n",
    "    real_eigenvalues_smooth2 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    # real_eigenvalues_smooth1[:,0] = torch.mean(real_eigenvalues_orig[:,0], dim=0)\n",
    "\n",
    "    \n",
    "    H_r_smooth2, C_r_smooth2 = compute_H_C_only(real_eigenvalues_smooth2, eigenvectors)\n",
    "    Gap_r_smooth2 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth2, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth2, 'C': C_r_smooth2, 'Gap': Gap_r_smooth2, \n",
    "        'Spec': real_eigenvalues_smooth2, 'Title': \"Real Data (Modified)\"\n",
    "    })\n",
    "\n",
    "    \n",
    "    total_rows = len(results)\n",
    "    print(f\"\\nGenerating Plots ({total_rows} rows x 5 columns)...\")\n",
    "    \n",
    "    # Col 1: C vs H\n",
    "    # Col 2: Gap\n",
    "    # Col 3: Spectrum\n",
    "    # Col 4: C vs C_orig (LogLog + Fit)\n",
    "    # Col 5: H vs H_orig (LogLog + Fit)\n",
    "    fig, axes = plt.subplots(total_rows, 5, figsize=(30, 4 * total_rows))\n",
    "    if total_rows == 1: axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        analyze_slope_and_plot(CH_slice,\n",
    "            res['H'], res['C'], res['Gap'], res['Spec'], res['Title'],\n",
    "            H_r_orig, C_r_orig,  \n",
    "            axes[i, 0], axes[i, 1], axes[i, 2], axes[i, 3], axes[i, 4],  \n",
    "            end_idx=k_target)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'h_holder' in locals():\n",
    "        CH_slice = torch.arange(0, 1500)\n",
    "        main(CH_slice, h_holder, a1=1.0, a2=1.6, a3=3.0, k_target=2560)\n",
    "    else:\n",
    "        print(\"Please define 'h_holder' (Tensor shape B, N, N) before running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69481ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_icml_style():\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix',  \n",
    "        'font.size': 12,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 14,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'legend.fontsize': 10,\n",
    "        'lines.linewidth': 1.5,\n",
    "        'lines.markersize': 4,\n",
    "        \n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.color': '#b0b0b0', #\n",
    "        'savefig.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "        'figure.autolayout': False, # \n",
    "        \n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "def format_ax(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(direction='out', length=4, width=1)\n",
    "\n",
    "\n",
    "\n",
    "def get_top_k_decomposition(h_holder, k=800):\n",
    "    print(f\"1. Performing Eigen Decomposition (Full Rank)...\")\n",
    "    h_holder = h_holder.to(device)\n",
    "    vals, vecs = torch.linalg.eigh(h_holder)\n",
    "    vals = torch.flip(vals, dims=[1])\n",
    "    vecs = torch.flip(vecs, dims=[2])\n",
    "    N = vals.shape[1]\n",
    "    actual_k = min(k, N)\n",
    "    print(f\"2. Filtering Top {actual_k} modes...\")\n",
    "    vals_k = vals[:, :actual_k]\n",
    "    vecs_k = vecs[:, :, :actual_k]\n",
    "    del vals, vecs\n",
    "    torch.cuda.empty_cache()\n",
    "    return vals_k, vecs_k\n",
    "\n",
    "def compute_H_C_only(eigenvalues, eigenvectors, chunk_size=16):\n",
    "    N_samples = eigenvalues.shape[0]\n",
    "    N_dim = eigenvectors.shape[1]\n",
    "    H_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "    C_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, N_samples, chunk_size):\n",
    "            end_idx = min(i + chunk_size, N_samples)\n",
    "            lam_chunk = eigenvalues[i:end_idx]\n",
    "            vec_chunk = eigenvectors[i:end_idx]\n",
    "            vec_chunk = torch.flip(vec_chunk, dims=[1]) \n",
    "            V_sq_chunk = vec_chunk ** 2\n",
    "            \n",
    "            H_batch_chunk = torch.matmul(V_sq_chunk, lam_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "            lam_sq_chunk = lam_chunk ** 2\n",
    "            C_batch_chunk = torch.matmul(V_sq_chunk, lam_sq_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            H_mean_accumulator += torch.sum(H_batch_chunk, dim=0).cpu().numpy()\n",
    "            C_mean_accumulator += torch.sum(C_batch_chunk, dim=0).cpu().numpy()\n",
    "            \n",
    "            del lam_chunk, vec_chunk, V_sq_chunk, H_batch_chunk, C_batch_chunk\n",
    "            \n",
    "    return H_mean_accumulator / N_samples, C_mean_accumulator / N_samples\n",
    "\n",
    "def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "    print(f\"Computing Gap Matrix (Batch Size={batch_size})...\")\n",
    "    B, N, num_modes = eigenvectors.shape \n",
    "    eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "    total_gap_sum = torch.zeros((N, num_modes), device=device)\n",
    "    with torch.no_grad():\n",
    "        for b_start in range(0, B, batch_size):\n",
    "            b_end = min(b_start + batch_size, B)\n",
    "            vec_chunk = eigenvectors[b_start:b_end] \n",
    "            val_chunk = eigenvalues[b_start:b_end]      \n",
    "            lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "            V_sq = vec_chunk ** 2\n",
    "            numerator = torch.cumsum(lam_sq * V_sq, dim=2) \n",
    "            total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "            denominator = total_energy \n",
    "            gap_chunk = numerator / denominator \n",
    "            total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "            del vec_chunk, val_chunk, lam_sq, V_sq, numerator, denominator, gap_chunk\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_gap_matrix = total_gap_sum / B\n",
    "    return avg_gap_matrix.cpu().numpy()\n",
    "\n",
    "def create_gap_from_real_spectrum(eigenvalues, idx = 10):\n",
    "    gap_spectrum = eigenvalues.clone()\n",
    "    gap_spectrum[:, idx:] = gap_spectrum[:, idx:] * 1e-5\n",
    "    return gap_spectrum\n",
    "\n",
    "\n",
    "\n",
    "def plot_comparison_loglog(ax, data_orig, data_new, label_name, CH_slice):\n",
    "\n",
    "    format_ax(ax) # \n",
    "    x = data_orig[CH_slice]\n",
    "    y = data_new[CH_slice]\n",
    "    \n",
    "    mask = (x > 0) & (y > 0)\n",
    "    x_clean, y_clean = x[mask], y[mask]\n",
    "\n",
    "    if len(x_clean) > 1:\n",
    "        log_x, log_y = np.log10(x_clean), np.log10(y_clean)\n",
    "        slope, intercept, r_val, _, _ = linregress(log_x, log_y)        \n",
    "        ax.scatter(x_clean, y_clean, s=2, facecolors='none', edgecolors='#1f77b4', alpha=0.6, linewidth=0.8, label='Data Points')\n",
    "        fit_y = 10**(intercept + slope * log_x)\n",
    "        ax.plot(x_clean, fit_y, color='#d62728', linestyle='-', linewidth=2.0, label=f'Fit: slope={slope:.2f}')\n",
    "        min_val = min(x_clean.min(), y_clean.min())\n",
    "        max_val = max(x_clean.max(), y_clean.max())\n",
    "        ref_line = np.linspace(min_val, max_val, 100)\n",
    "        ax.plot(ref_line, ref_line, 'k--', linewidth=1.0, alpha=0.6, label='y=x')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')    \n",
    "    ax.set_xlabel(f'Original {label_name}')\n",
    "    ax.set_ylabel(f'Current {label_name}')\n",
    "    ax.set_title(f'{label_name} Comparison')\n",
    "    \n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.9, edgecolor='gray', fontsize=9)\n",
    "\n",
    "\n",
    "def analyze_slope_and_plot(CH_slice, H, C, gap_matrix, spectrum_data, row_title, \n",
    "                           H_ref, C_ref, \n",
    "                           ax_scatter, ax_gap, ax_spectrum, ax_comp_c, ax_comp_h,\n",
    "                           end_idx=800):\n",
    "    \n",
    "    # --- 1. C_ii vs H_ii Scatter Plot ---\n",
    "    format_ax(ax_scatter)\n",
    "    x_data = H[CH_slice]\n",
    "    y_data = C[CH_slice]\n",
    "    mask = (x_data > 0) & (y_data > 0)\n",
    "    x_data, y_data = x_data[mask], y_data[mask]\n",
    "    \n",
    "    if len(x_data) > 1:\n",
    "        log_x, log_y = np.log10(x_data), np.log10(y_data)\n",
    "        slope, intercept, _, _, _ = linregress(log_x, log_y)\n",
    "        \n",
    "        ax_scatter.scatter(x_data, y_data, s=2, alpha=0.5, color='#000080', label='Data', edgecolors='none')\n",
    "        \n",
    "        fit_line_y = 10**(intercept + slope * log_x)\n",
    "        ax_scatter.plot(x_data, fit_line_y, color='#d62728', linestyle='-', linewidth=1.5, label=f'Fit: {slope:.2f}')\n",
    "        \n",
    "        mid_x, mid_y = np.mean(log_x), np.mean(log_y)\n",
    "        ref_line_x = np.logspace(min(log_x), max(log_x), 100)\n",
    "        \n",
    "        ref_line_y1 = 10**(1.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y1, 'k--', linewidth=1.0, label='Slope=1')\n",
    "        \n",
    "        ref_line_y2 = 10**(2.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y2, color='green', linestyle=':', linewidth=1.5, label='Slope=2')\n",
    "    \n",
    "    ax_scatter.set_xscale('log')\n",
    "    ax_scatter.set_yscale('log')\n",
    "    ax_scatter.set_xlabel(r'$H_{ii}$')\n",
    "    ax_scatter.set_ylabel(r'$C_{ii}$')\n",
    "    ax_scatter.set_title(f\"Scalability ({row_title})\") \n",
    "    ax_scatter.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "    \n",
    "    # --- 2. Gap Curve Plot ---\n",
    "    format_ax(ax_gap)\n",
    "    real_k = gap_matrix.shape[1]\n",
    "    k_values = np.arange(1, real_k + 1)\n",
    "    avg_gap_curve = np.mean(gap_matrix[:1500], axis=0)\n",
    "    \n",
    "    indices_to_plot = [1, 10, 50, 100, 400, 1000]\n",
    "    colors_gap = plt.cm.viridis(np.linspace(0, 0.9, len(indices_to_plot))) \n",
    "    \n",
    "    for idx, color in zip(indices_to_plot, colors_gap):\n",
    "        if idx < gap_matrix.shape[0]:\n",
    "            ax_gap.semilogx(k_values, gap_matrix[idx, :], color=color, linewidth=1.2, alpha=0.7, label=f'i={idx+1}')\n",
    "            \n",
    "    ax_gap.semilogx(k_values, avg_gap_curve, 'k--', linewidth=2.0, alpha=1.0, label='Avg')\n",
    "    \n",
    "    ax_gap.legend(loc='lower right', fontsize=8, ncol=2, frameon=False) \n",
    "    ax_gap.set_title(\"Gap Metric\")\n",
    "    ax_gap.set_xlabel('k (Cutoff)')\n",
    "    ax_gap.set_ylabel('Cum. Distribution')\n",
    "    ax_gap.set_ylim(0, 1.1)\n",
    "    \n",
    "    # --- 3. Spectrum Plot (Sampled) ---\n",
    "    format_ax(ax_spectrum)\n",
    "    if isinstance(spectrum_data, torch.Tensor):\n",
    "        spec_np = spectrum_data.detach().cpu().numpy()\n",
    "    else:\n",
    "        spec_np = spectrum_data\n",
    "        \n",
    "    B_samples = spec_np.shape[0]\n",
    "    num_classes = 10 \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, num_classes))\n",
    "    ranks = np.arange(1, spec_np.shape[1] + 1)\n",
    "    \n",
    "    selected_indices = np.linspace(0, B_samples-1, num_classes, dtype=int)\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        ax_spectrum.loglog(ranks, spec_np[idx], color=colors[i], alpha=0.7, linewidth=1.5)\n",
    "            \n",
    "    ax_spectrum.axvline(x=10, color='gray', linestyle=':', linewidth=1.0)\n",
    "    ax_spectrum.set_title('Spectrum (Sampled)')\n",
    "    ax_spectrum.set_xlabel('Rank')\n",
    "    ax_spectrum.set_ylabel(r'$|\\lambda_i|$')\n",
    "\n",
    "    # --- 4. NEW: C_ii Comparison ---\n",
    "    plot_comparison_loglog(ax_comp_c, C_ref, C, r'$C_{ii}$', CH_slice)\n",
    "\n",
    "    # --- 5. NEW: H_ii Comparison ---\n",
    "    plot_comparison_loglog(ax_comp_h, H_ref, H, r'$H_{ii}$', CH_slice)\n",
    "\n",
    "\n",
    "\n",
    "def main(CH_slice, h_holder_input=None, fig_title=\"Neural Collapse Spectral Analysis\"):\n",
    "\n",
    "    set_icml_style()\n",
    "    \n",
    "    h_holder = h_holder_input\n",
    "    B, N, _ = h_holder.shape\n",
    "    print(f\"Processing input data: B={B}, N={N}\")\n",
    "\n",
    "    torch.backends.cuda.preferred_linalg_library('magma')\n",
    "    k_target_actual = min(N, 2000) \n",
    "    real_eigenvalues_orig, eigenvectors = get_top_k_decomposition(h_holder, k=k_target_actual)\n",
    "    \n",
    "    del h_holder \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # --- Baseline ---\n",
    "    print(\"\\n--- Processing Real Data (Original) ---\")\n",
    "    H_r_orig, C_r_orig = compute_H_C_only(real_eigenvalues_orig, eigenvectors)\n",
    "    Gap_r_orig = compute_full_gap_matrix_efficient(real_eigenvalues_orig, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_orig, 'C': C_r_orig, 'Gap': Gap_r_orig, \n",
    "        'Spec': real_eigenvalues_orig, 'Title': \"Original\"\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- Processing Real Data (Cut 1) ---\")\n",
    "    real_eigenvalues_smooth2 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    H_r_smooth2, C_r_smooth2 = compute_H_C_only(real_eigenvalues_smooth2, eigenvectors)\n",
    "    Gap_r_smooth2 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth2, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth2, 'C': C_r_smooth2, 'Gap': Gap_r_smooth2, \n",
    "        'Spec': real_eigenvalues_smooth2, 'Title': f\"Cut @ k=1\"\n",
    "    })\n",
    "\n",
    "\n",
    "    print(\"\\n--- Processing Real Data (Reshaped) ---\")\n",
    "\n",
    "    real_eigenvalues_smooth3 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    real_eigenvalues_smooth3[:,0] = torch.mean(real_eigenvalues_smooth3[:,0], dim=0)\n",
    "\n",
    "    \n",
    "    H_r_smooth3, C_r_smooth3 = compute_H_C_only(real_eigenvalues_smooth3, eigenvectors)\n",
    "    Gap_r_smooth3 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth3, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth3, 'C': C_r_smooth3, 'Gap': Gap_r_smooth3, \n",
    "        'Spec': real_eigenvalues_smooth3, 'Title': f\"Cut @ k=1 and Collapse to the mean\"\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    total_rows = len(results)\n",
    "    print(f\"\\nGenerating Plots...\")    \n",
    "    fig, axes = plt.subplots(total_rows, 5, figsize=(20, 3.5 * total_rows))\n",
    "    if total_rows == 1: \n",
    "        axes = np.expand_dims(axes, 0)\n",
    "\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        analyze_slope_and_plot(CH_slice,\n",
    "            res['H'], res['C'], res['Gap'], res['Spec'], res['Title'],\n",
    "            H_r_orig, C_r_orig, \n",
    "            axes[i, 0], axes[i, 1], axes[i, 2], axes[i, 3], axes[i, 4],\n",
    "            end_idx=k_target_actual)\n",
    "\n",
    "    fig.suptitle(fig_title, fontsize=20, fontweight='bold', fontfamily='serif', y=1.02)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Spectrum_cutoff.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf',          \n",
    "        bbox_inches='tight',   \n",
    "        pad_inches=0.2,       \n",
    "        dpi=300               \n",
    "    ) \n",
    "    plt.show()\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if 'h_holder' in locals():\n",
    "        MY_TITLE = \"Effect of Spectrum Cutoff on C-H Scaling Law\"\n",
    "        CH_slice = torch.arange(0, 1500) \n",
    "        main(CH_slice, h_holder, fig_title=MY_TITLE)\n",
    "    else:\n",
    "        print(\"Wait: 'h_holder' is not defined. Please define input tensor first.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_icml_appendix_style():\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix', \n",
    "        \n",
    "        'font.size': 18,           \n",
    "        'axes.labelsize': 20,      \n",
    "        'axes.titlesize': 22,      \n",
    "        'xtick.labelsize': 16,     \n",
    "        'ytick.labelsize': 16,\n",
    "        'legend.fontsize': 16,     \n",
    "        \n",
    "\n",
    "        'lines.linewidth': 3.0,   \n",
    "        'lines.markersize': 8,     \n",
    "        'axes.linewidth': 2.0,   \n",
    "\n",
    "        'xtick.major.size': 8,\n",
    "        'xtick.major.width': 1.5,\n",
    "        'ytick.major.size': 8,\n",
    "        'ytick.major.width': 1.5,\n",
    "        \n",
    "\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.4,\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.linewidth': 1.0,\n",
    "        \n",
    "\n",
    "        'savefig.dpi': 300,\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "def format_boxed_ax(ax):\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.0)  \n",
    "        spine.set_color('black')\n",
    "    ax.tick_params(direction='in', width=1.5, length=6, colors='black', grid_alpha=0.4)\n",
    "\n",
    "\n",
    "def get_top_k_decomposition(h_holder, k=800):\n",
    "    print(f\"1. Performing Eigen Decomposition (Full Rank)...\")\n",
    "    h_holder = h_holder.to(device)\n",
    "    vals, vecs = torch.linalg.eigh(h_holder)\n",
    "    vals = torch.flip(vals, dims=[1])\n",
    "    vecs = torch.flip(vecs, dims=[2])\n",
    "    N = vals.shape[1]\n",
    "    actual_k = min(k, N)\n",
    "    print(f\"2. Filtering Top {actual_k} modes...\")\n",
    "    vals_k = vals[:, :actual_k]\n",
    "    vecs_k = vecs[:, :, :actual_k]\n",
    "    del vals, vecs\n",
    "    torch.cuda.empty_cache()\n",
    "    return vals_k, vecs_k\n",
    "\n",
    "def compute_H_C_only(eigenvalues, eigenvectors, chunk_size=16):\n",
    "    N_samples = eigenvalues.shape[0]\n",
    "    N_dim = eigenvectors.shape[1]\n",
    "    H_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "    C_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, N_samples, chunk_size):\n",
    "            end_idx = min(i + chunk_size, N_samples)\n",
    "            lam_chunk = eigenvalues[i:end_idx]\n",
    "            vec_chunk = eigenvectors[i:end_idx]\n",
    "            vec_chunk = torch.flip(vec_chunk, dims=[1]) \n",
    "            V_sq_chunk = vec_chunk ** 2\n",
    "            \n",
    "            H_batch_chunk = torch.matmul(V_sq_chunk, lam_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "            lam_sq_chunk = lam_chunk ** 2\n",
    "            C_batch_chunk = torch.matmul(V_sq_chunk, lam_sq_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            H_mean_accumulator += torch.sum(H_batch_chunk, dim=0).cpu().numpy()\n",
    "            C_mean_accumulator += torch.sum(C_batch_chunk, dim=0).cpu().numpy()\n",
    "            \n",
    "            del lam_chunk, vec_chunk, V_sq_chunk, H_batch_chunk, C_batch_chunk\n",
    "            \n",
    "    return H_mean_accumulator / N_samples, C_mean_accumulator / N_samples\n",
    "\n",
    "def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "    print(f\"Computing Gap Matrix (Batch Size={batch_size})...\")\n",
    "    B, N, num_modes = eigenvectors.shape \n",
    "    eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "    total_gap_sum = torch.zeros((N, num_modes), device=device)\n",
    "    with torch.no_grad():\n",
    "        for b_start in range(0, B, batch_size):\n",
    "            b_end = min(b_start + batch_size, B)\n",
    "            vec_chunk = eigenvectors[b_start:b_end] \n",
    "            val_chunk = eigenvalues[b_start:b_end]      \n",
    "            lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "            V_sq = vec_chunk ** 2\n",
    "            numerator = torch.cumsum(lam_sq * V_sq, dim=2) \n",
    "            total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "            denominator = total_energy \n",
    "            gap_chunk = numerator / denominator \n",
    "            total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "            del vec_chunk, val_chunk, lam_sq, V_sq, numerator, denominator, gap_chunk\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_gap_matrix = total_gap_sum / B\n",
    "    return avg_gap_matrix.cpu().numpy()\n",
    "\n",
    "def create_gap_from_real_spectrum(eigenvalues, idx = 10):\n",
    "    gap_spectrum = eigenvalues.clone()\n",
    "    gap_spectrum[:, idx:] = gap_spectrum[:, idx:] * 1e-5\n",
    "    return gap_spectrum\n",
    "\n",
    "\n",
    "\n",
    "def plot_comparison_loglog(ax, data_orig, data_new, label_name, CH_slice):\n",
    "\n",
    "    format_boxed_ax(ax) \n",
    "    x = data_orig[CH_slice]\n",
    "    y = data_new[CH_slice]\n",
    "    \n",
    "    mask = (x > 0) & (y > 0)\n",
    "    x_clean, y_clean = x[mask], y[mask]\n",
    "\n",
    "    if len(x_clean) > 1:\n",
    "        log_x, log_y = np.log10(x_clean), np.log10(y_clean)\n",
    "        slope, intercept, r_val, _, _ = linregress(log_x, log_y)\n",
    "\n",
    "        ax.scatter(x_clean, y_clean, s=3, facecolors='none', edgecolors='#1f77b4', \n",
    "                   alpha=0.7, linewidth=0.5, label='Data Points')\n",
    "        \n",
    "\n",
    "        fit_y = 10**(intercept + slope * log_x)\n",
    "        ax.plot(x_clean, fit_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: slope={slope:.2f}')\n",
    "\n",
    "        min_val = min(x_clean.min(), y_clean.min())\n",
    "        max_val = max(x_clean.max(), y_clean.max())\n",
    "        ref_line = np.linspace(min_val, max_val, 100)\n",
    "        ax.plot(ref_line, ref_line, 'k--', linewidth=2.0, alpha=0.6, label='y=x')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax.set_xlabel(f'Original {label_name}')\n",
    "    ax.set_ylabel(f'Current {label_name}')\n",
    "    ax.set_title(f'{label_name} Comparison')\n",
    "    \n",
    "    # 图例字体加大\n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.9, edgecolor='black', fancybox=False)\n",
    "\n",
    "\n",
    "def analyze_slope_and_plot(CH_slice, H, C, gap_matrix, spectrum_data, row_title, \n",
    "                           H_ref, C_ref, \n",
    "                           ax_scatter, ax_gap, ax_spectrum, ax_comp_c, ax_comp_h,\n",
    "                           end_idx=800):\n",
    "    \n",
    "    # --- 1. C_ii vs H_ii Scatter Plot ---\n",
    "    format_boxed_ax(ax_scatter)\n",
    "    x_data = H[CH_slice]\n",
    "    y_data = C[CH_slice]\n",
    "    mask = (x_data > 0) & (y_data > 0)\n",
    "    x_data, y_data = x_data[mask], y_data[mask]\n",
    "    \n",
    "    if len(x_data) > 1:\n",
    "        log_x, log_y = np.log10(x_data), np.log10(y_data)\n",
    "        slope, intercept, _, _, _ = linregress(log_x, log_y)\n",
    "\n",
    "        ax_scatter.scatter(x_data, y_data, s=3, alpha=0.6, color='#000080', label='Data', edgecolors='none')\n",
    "\n",
    "        fit_line_y = 10**(intercept + slope * log_x)\n",
    "        ax_scatter.plot(x_data, fit_line_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: {slope:.2f}')\n",
    "\n",
    "        mid_x, mid_y = np.mean(log_x), np.mean(log_y)\n",
    "        ref_line_x = np.logspace(min(log_x), max(log_x), 100)\n",
    "        \n",
    "        ref_line_y1 = 10**(1.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y1, 'k--', linewidth=2.0, label='Slope=1')\n",
    "        \n",
    "        ref_line_y2 = 10**(2.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y2, color='green', linestyle=':', linewidth=3.0, label='Slope=2')\n",
    "    \n",
    "    ax_scatter.set_xscale('log')\n",
    "    ax_scatter.set_yscale('log')\n",
    "    ax_scatter.set_xlabel(r'$H_{ii}$')\n",
    "    ax_scatter.set_ylabel(r'$C_{ii}$')\n",
    "    ax_scatter.set_title(f\"Scalability ({row_title})\", fontweight='bold') \n",
    "    ax_scatter.legend(loc='upper left', frameon=True, edgecolor='black', fancybox=False)\n",
    "    \n",
    "    # --- 2. Gap Curve Plot ---\n",
    "    format_boxed_ax(ax_gap)\n",
    "    real_k = gap_matrix.shape[1]\n",
    "    k_values = np.arange(1, real_k + 1)\n",
    "    avg_gap_curve = np.mean(gap_matrix[:1500], axis=0)\n",
    "    \n",
    "    indices_to_plot = [1, 10, 50, 100, 400, 1000]\n",
    "    colors_gap = plt.cm.viridis(np.linspace(0, 0.9, len(indices_to_plot))) \n",
    "    \n",
    "    for idx, color in zip(indices_to_plot, colors_gap):\n",
    "        if idx < gap_matrix.shape[0]:\n",
    "            ax_gap.semilogx(k_values, gap_matrix[idx, :], color=color, linewidth=2.0, alpha=0.8, label=f'i={idx+1}')\n",
    "            \n",
    "    ax_gap.semilogx(k_values, avg_gap_curve, 'k--', linewidth=3.5, alpha=1.0, label='Avg')\n",
    "\n",
    "    ax_gap.legend(loc='lower right', ncol=2, frameon=True, edgecolor='black', fancybox=False) \n",
    "    ax_gap.set_title(\"Gap Metric\")\n",
    "    ax_gap.set_xlabel('k (Cutoff)')\n",
    "    ax_gap.set_ylabel('Cum. Distribution')\n",
    "    ax_gap.set_ylim(-0.05, 1.1)\n",
    "    \n",
    "\n",
    "    format_boxed_ax(ax_spectrum)\n",
    "    if isinstance(spectrum_data, torch.Tensor):\n",
    "        spec_np = spectrum_data.detach().cpu().numpy()\n",
    "    else:\n",
    "        spec_np = spectrum_data\n",
    "        \n",
    "    B_samples = spec_np.shape[0]\n",
    "    num_classes = 8 \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, num_classes))\n",
    "    ranks = np.arange(1, spec_np.shape[1] + 1)\n",
    "    \n",
    "    selected_indices = np.linspace(0, B_samples-1, num_classes, dtype=int)\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        ax_spectrum.loglog(ranks, spec_np[idx], color=colors[i], alpha=0.8, linewidth=2.0)\n",
    "            \n",
    "    ax_spectrum.axvline(x=10, color='gray', linestyle=':', linewidth=2.5)\n",
    "    ax_spectrum.set_title('Spectrum (Sampled)')\n",
    "    ax_spectrum.set_xlabel('Rank')\n",
    "    ax_spectrum.set_ylabel(r'$|\\lambda_i|$')\n",
    "\n",
    "\n",
    "    plot_comparison_loglog(ax_comp_c, C_ref, C, r'$C_{ii}$', CH_slice)\n",
    "\n",
    "\n",
    "    plot_comparison_loglog(ax_comp_h, H_ref, H, r'$H_{ii}$', CH_slice)\n",
    "\n",
    "\n",
    "\n",
    "def main(CH_slice, h_holder_input=None, fig_title=\"Neural Collapse Spectral Analysis\"):\n",
    "\n",
    "    set_icml_appendix_style()\n",
    "    \n",
    "    h_holder = h_holder_input\n",
    "    B, N, _ = h_holder.shape\n",
    "    print(f\"Processing input data: B={B}, N={N}\")\n",
    "\n",
    "\n",
    "    torch.backends.cuda.preferred_linalg_library('magma')\n",
    "    k_target_actual = min(N, 2000) \n",
    "    real_eigenvalues_orig, eigenvectors = get_top_k_decomposition(h_holder, k=k_target_actual)\n",
    "    \n",
    "    del h_holder \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # --- Baseline ---\n",
    "    print(\"\\n--- Processing Real Data (Original) ---\")\n",
    "    H_r_orig, C_r_orig = compute_H_C_only(real_eigenvalues_orig, eigenvectors)\n",
    "    Gap_r_orig = compute_full_gap_matrix_efficient(real_eigenvalues_orig, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_orig, 'C': C_r_orig, 'Gap': Gap_r_orig, \n",
    "        'Spec': real_eigenvalues_orig, 'Title': \"Original\"\n",
    "    })\n",
    "    \n",
    "    # --- Modified 2 (Gap cut at 1) ---\n",
    "    print(\"\\n--- Processing Real Data (Cut 1) ---\")\n",
    "    real_eigenvalues_smooth2 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    H_r_smooth2, C_r_smooth2 = compute_H_C_only(real_eigenvalues_smooth2, eigenvectors)\n",
    "    Gap_r_smooth2 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth2, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth2, 'C': C_r_smooth2, 'Gap': Gap_r_smooth2, \n",
    "        'Spec': real_eigenvalues_smooth2, 'Title': f\"Cut @ k=1\"\n",
    "    })\n",
    "\n",
    "    # --- Real Data (Reshaped) ---\n",
    "    print(\"\\n--- Processing Real Data (Reshaped) ---\")\n",
    "    real_eigenvalues_smooth3 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    real_eigenvalues_smooth3[:,0] = torch.mean(real_eigenvalues_smooth3[:,0], dim=0)\n",
    "\n",
    "    H_r_smooth3, C_r_smooth3 = compute_H_C_only(real_eigenvalues_smooth3, eigenvectors)\n",
    "    Gap_r_smooth3 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth3, eigenvectors)\n",
    "    \n",
    "    results.append({\n",
    "        'H': H_r_smooth3, 'C': C_r_smooth3, 'Gap': Gap_r_smooth3, \n",
    "        'Spec': real_eigenvalues_smooth3, 'Title': f\"Cut @ k=1 & Mean Collapse\"\n",
    "    })\n",
    "\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. Plotting with Overall Title\n",
    "    # ==========================================\n",
    "    total_rows = len(results)\n",
    "    print(f\"\\nGenerating Plots...\")\n",
    "\n",
    "    fig, axes = plt.subplots(total_rows, 5, figsize=(24, 5.0 * total_rows), constrained_layout=True)\n",
    "    \n",
    "    if total_rows == 1: \n",
    "        axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        analyze_slope_and_plot(CH_slice,\n",
    "            res['H'], res['C'], res['Gap'], res['Spec'], res['Title'],\n",
    "            H_r_orig, C_r_orig, \n",
    "            axes[i, 0], axes[i, 1], axes[i, 2], axes[i, 3], axes[i, 4],\n",
    "            end_idx=k_target_actual)\n",
    "    \n",
    "\n",
    "    fig.suptitle(fig_title, fontsize=28, fontweight='bold', fontfamily='serif')\n",
    "\n",
    "    try:\n",
    "        save_dir = f\"ICML_Figures/{config['model']}_{config['dataset']}_{config['lss_fn']}\"\n",
    "    except:\n",
    "        save_dir = \"ICML_Figures/Debug\"\n",
    "        \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Spectrum_cutoff_appendix.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    print(f\"Saving to {save_path} ...\")\n",
    "    plt.savefig(\n",
    "        save_path, \n",
    "        format='pdf', \n",
    "        bbox_inches='tight', \n",
    "        pad_inches=0.2, \n",
    "        dpi=300 \n",
    "    ) \n",
    "    plt.show()\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if 'h_holder' in locals():\n",
    "\n",
    "        MY_TITLE = \"Effect of Spectrum Cutoff on C-H Scaling Law\"\n",
    "        \n",
    "\n",
    "        CH_slice = torch.arange(0, 1500) \n",
    "        main(CH_slice, h_holder, fig_title=MY_TITLE)\n",
    "    else:\n",
    "        print(\"Wait: 'h_holder' is not defined. Please define input tensor first.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_icml_appendix_style():\n",
    "\n",
    "    plt.rcParams.update({\n",
    "\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix', \n",
    "        \n",
    "        'font.size': 18,\n",
    "        'axes.labelsize': 20,\n",
    "        'axes.titlesize': 22,\n",
    "        'xtick.labelsize': 16,\n",
    "        'ytick.labelsize': 16,\n",
    "        'legend.fontsize': 16,\n",
    "        \n",
    "\n",
    "        'lines.linewidth': 3.0,\n",
    "        'lines.markersize': 8,\n",
    "        'axes.linewidth': 2.0,\n",
    "        \n",
    "\n",
    "        'xtick.major.size': 8,\n",
    "        'xtick.major.width': 1.5,\n",
    "        'ytick.major.size': 8,\n",
    "        'ytick.major.width': 1.5,\n",
    "\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.4,\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.linewidth': 1.0,\n",
    "\n",
    "        'savefig.dpi': 300,\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "def format_boxed_ax(ax):\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.0)\n",
    "        spine.set_color('black')\n",
    "    ax.tick_params(direction='in', width=1.5, length=6, colors='black', grid_alpha=0.4)\n",
    "\n",
    "\n",
    "\n",
    "def get_top_k_decomposition(h_holder, k=800):\n",
    "    print(f\"1. Performing Eigen Decomposition (Full Rank)...\")\n",
    "    h_holder = h_holder.to(device)\n",
    "    vals, vecs = torch.linalg.eigh(h_holder)\n",
    "    vals = torch.flip(vals, dims=[1])\n",
    "    vecs = torch.flip(vecs, dims=[2])\n",
    "    N = vals.shape[1]\n",
    "    actual_k = min(k, N)\n",
    "    print(f\"2. Filtering Top {actual_k} modes...\")\n",
    "    vals_k = vals[:, :actual_k]\n",
    "    vecs_k = vecs[:, :, :actual_k]\n",
    "    del vals, vecs\n",
    "    torch.cuda.empty_cache()\n",
    "    return vals_k, vecs_k\n",
    "\n",
    "def compute_H_C_only(eigenvalues, eigenvectors, chunk_size=16):\n",
    "    N_samples = eigenvalues.shape[0]\n",
    "    N_dim = eigenvectors.shape[1]\n",
    "    H_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "    C_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, N_samples, chunk_size):\n",
    "            end_idx = min(i + chunk_size, N_samples)\n",
    "            lam_chunk = eigenvalues[i:end_idx]\n",
    "            vec_chunk = eigenvectors[i:end_idx]\n",
    "            vec_chunk = torch.flip(vec_chunk, dims=[1]) \n",
    "            V_sq_chunk = vec_chunk ** 2\n",
    "            \n",
    "            H_batch_chunk = torch.matmul(V_sq_chunk, lam_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "            lam_sq_chunk = lam_chunk ** 2\n",
    "            C_batch_chunk = torch.matmul(V_sq_chunk, lam_sq_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            H_mean_accumulator += torch.sum(H_batch_chunk, dim=0).cpu().numpy()\n",
    "            C_mean_accumulator += torch.sum(C_batch_chunk, dim=0).cpu().numpy()\n",
    "            \n",
    "            del lam_chunk, vec_chunk, V_sq_chunk, H_batch_chunk, C_batch_chunk\n",
    "            \n",
    "    return H_mean_accumulator / N_samples, C_mean_accumulator / N_samples\n",
    "\n",
    "# def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "#     print(f\"Computing Gap Matrix (Batch Size={batch_size})...\")\n",
    "#     B, N, num_modes = eigenvectors.shape \n",
    "#     eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "#     total_gap_sum = torch.zeros((N, num_modes), device=device)\n",
    "#     with torch.no_grad():\n",
    "#         for b_start in range(0, B, batch_size):\n",
    "#             b_end = min(b_start + batch_size, B)\n",
    "#             vec_chunk = eigenvectors[b_start:b_end] \n",
    "#             val_chunk = eigenvalues[b_start:b_end]      \n",
    "#             lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "#             V_sq = vec_chunk ** 2\n",
    "#             numerator = torch.cumsum(lam_sq * V_sq, dim=2) \n",
    "#             total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "#             denominator = total_energy \n",
    "#             gap_chunk = numerator / denominator \n",
    "#             total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "#             del vec_chunk, val_chunk, lam_sq, V_sq, numerator, denominator, gap_chunk\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "#     avg_gap_matrix = total_gap_sum / B\n",
    "#     return avg_gap_matrix.cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "    print(f\"Computing Gap Matrix (High Precision, Batch Size={batch_size})...\")\n",
    "    B, N, num_modes = eigenvectors.shape \n",
    "    eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "    \n",
    "    total_gap_sum = torch.zeros((N, num_modes), device=device, dtype=torch.float64)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b_start in range(0, B, batch_size):\n",
    "            b_end = min(b_start + batch_size, B)\n",
    "            \n",
    "            vec_chunk = eigenvectors[b_start:b_end].to(torch.float64) \n",
    "            val_chunk = eigenvalues[b_start:b_end].to(torch.float64)\n",
    "            \n",
    "            lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "            V_sq = vec_chunk ** 2\n",
    "            \n",
    "            energy_contribution = lam_sq * V_sq\n",
    "            numerator = torch.cumsum(energy_contribution, dim=2) \n",
    "            \n",
    "            total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "            \n",
    "            gap_chunk = numerator / (total_energy) \n",
    "            \n",
    "            total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "            \n",
    "            del vec_chunk, val_chunk, lam_sq, V_sq, numerator, total_energy, gap_chunk\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_gap_matrix = total_gap_sum / B\n",
    "    return avg_gap_matrix.cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_gap_from_real_spectrum(eigenvalues, idx = 10):\n",
    "\n",
    "    gap_spectrum = eigenvalues.clone()\n",
    "    gap_spectrum[:, idx:] = gap_spectrum[:, idx:] * 1e-5\n",
    "    return gap_spectrum\n",
    "\n",
    "def create_stiff_mean_spectrum(eigenvalues, idx=1, threshold_ratio=0.1, meancollapse=False):\n",
    "\n",
    "    new_spectrum = eigenvalues.clone()\n",
    "    new_spectrum[:, idx:] = new_spectrum[:, idx:] * 1e-5\n",
    "    \n",
    "\n",
    "    lam_0 = new_spectrum[:, 0]\n",
    "\n",
    "    threshold = torch.max(lam_0) * threshold_ratio\n",
    "    \n",
    "    stiff_mask = lam_0 > threshold\n",
    "    non_stiff_mask = ~stiff_mask\n",
    "\n",
    "    if stiff_mask.sum() > 0 and meancollapse:\n",
    "        stiff_mean = torch.mean(lam_0[stiff_mask])\n",
    "        print(f\"   [Stiff Analysis] Threshold: {threshold:.4f}, Count: {stiff_mask.sum().item()}/{len(lam_0)}, Mean Val: {stiff_mean:.4f}\")\n",
    "\n",
    "        new_spectrum[stiff_mask, 0] = stiff_mean\n",
    "    if non_stiff_mask.sum() > 0:\n",
    "\n",
    "        print(f\"   [Stiff Analysis] Suppressing {non_stiff_mask.sum().item()} Non-Stiff samples by 1e-5.\")\n",
    "        new_spectrum[non_stiff_mask, 0] = new_spectrum[non_stiff_mask, 0] * 1e-3\n",
    "        \n",
    "    return new_spectrum\n",
    "\n",
    "\n",
    "\n",
    "def plot_comparison_loglog(ax, data_orig, data_new, label_name, CH_slice):\n",
    "    format_boxed_ax(ax)\n",
    "    x = data_orig[CH_slice]\n",
    "    y = data_new[CH_slice]\n",
    "    \n",
    "    mask = (x > 0) & (y > 0)\n",
    "    x_clean, y_clean = x[mask], y[mask]\n",
    "\n",
    "    if len(x_clean) > 1:\n",
    "        log_x, log_y = np.log10(x_clean), np.log10(y_clean)\n",
    "        slope, intercept, r_val, _, _ = linregress(log_x, log_y)\n",
    "        \n",
    "        ax.scatter(x_clean, y_clean, s=3, facecolors='none', edgecolors='#1f77b4', \n",
    "                   alpha=0.7, linewidth=0.5, label='Data Points')\n",
    "        \n",
    "        fit_y = 10**(intercept + slope * log_x)\n",
    "        ax.plot(x_clean, fit_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: slope={slope:.2f}')\n",
    "        \n",
    "        min_val = min(x_clean.min(), y_clean.min())\n",
    "        max_val = max(x_clean.max(), y_clean.max())\n",
    "        ref_line = np.linspace(min_val, max_val, 100)\n",
    "        ax.plot(ref_line, ref_line, 'k--', linewidth=2.0, alpha=0.6, label='y=x')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(f'Original {label_name}')\n",
    "    ax.set_ylabel(f'Current {label_name}')\n",
    "    ax.set_title(f'{label_name} Comparison')\n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.9, edgecolor='black', fancybox=False)\n",
    "\n",
    "\n",
    "def analyze_slope_and_plot(CH_slice, H, C, gap_matrix, spectrum_data, row_title, \n",
    "                           H_ref, C_ref, \n",
    "                           ax_scatter, ax_gap, ax_spectrum, ax_comp_c, ax_comp_h,\n",
    "                           end_idx=800):\n",
    "    \n",
    "    # --- 1. C_ii vs H_ii Scatter ---\n",
    "    format_boxed_ax(ax_scatter)\n",
    "    x_data = H[CH_slice]\n",
    "    y_data = C[CH_slice]\n",
    "    mask = (x_data > 0) & (y_data > 0)\n",
    "    x_data, y_data = x_data[mask], y_data[mask]\n",
    "    \n",
    "    if len(x_data) > 1:\n",
    "        log_x, log_y = np.log10(x_data), np.log10(y_data)\n",
    "        slope, intercept, _, _, _ = linregress(log_x, log_y)\n",
    "        ax_scatter.scatter(x_data, y_data, s=3, alpha=0.6, color='#000080', label='Data', edgecolors='none')\n",
    "        fit_line_y = 10**(intercept + slope * log_x)\n",
    "        ax_scatter.plot(x_data, fit_line_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: {slope:.2f}')\n",
    "        \n",
    "        mid_x, mid_y = np.mean(log_x), np.mean(log_y)\n",
    "        ref_line_x = np.logspace(min(log_x), max(log_x), 100)\n",
    "        ref_line_y1 = 10**(1.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y1, 'k--', linewidth=2.0, label='Slope=1')\n",
    "        ref_line_y2 = 10**(2.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y2, color='green', linestyle=':', linewidth=3.0, label='Slope=2')\n",
    "    \n",
    "    ax_scatter.set_xscale('log')\n",
    "    ax_scatter.set_yscale('log')\n",
    "    ax_scatter.set_xlabel(r'$H_{ii}$')\n",
    "    ax_scatter.set_ylabel(r'$C_{ii}$')\n",
    "    ax_scatter.set_title(f\"Scalability ({row_title})\", fontweight='bold') \n",
    "    ax_scatter.legend(loc='upper left', frameon=True, edgecolor='black', fancybox=False)\n",
    "    \n",
    "    # --- 2. Gap Curve ---\n",
    "    format_boxed_ax(ax_gap)\n",
    "    real_k = gap_matrix.shape[1]\n",
    "    k_values = np.arange(1, real_k + 1)\n",
    "    avg_gap_curve = np.mean(gap_matrix[:1500], axis=0)\n",
    "    \n",
    "    indices_to_plot = [1, 10, 50, 100, 400, 1000]\n",
    "    colors_gap = plt.cm.viridis(np.linspace(0, 0.9, len(indices_to_plot))) \n",
    "    for idx, color in zip(indices_to_plot, colors_gap):\n",
    "        if idx < gap_matrix.shape[0]:\n",
    "            ax_gap.semilogx(k_values, gap_matrix[idx, :], color=color, linewidth=2.0, alpha=0.8, label=f'i={idx+1}')\n",
    "    ax_gap.semilogx(k_values, avg_gap_curve, 'k--', linewidth=3.5, alpha=1.0, label='Avg')\n",
    "    ax_gap.legend(loc='lower right', ncol=2, frameon=True, edgecolor='black', fancybox=False) \n",
    "    ax_gap.set_title(\"Gap Metric\")\n",
    "    ax_gap.set_xlabel('k (Cutoff)')\n",
    "    ax_gap.set_ylabel('Cum. Distribution')\n",
    "    ax_gap.set_ylim(-0.05, 1.1)\n",
    "    \n",
    "    # --- 3. Spectrum Plot ---\n",
    "    format_boxed_ax(ax_spectrum)\n",
    "    if isinstance(spectrum_data, torch.Tensor):\n",
    "        spec_np = spectrum_data.detach().cpu().numpy()\n",
    "    else:\n",
    "        spec_np = spectrum_data\n",
    "    B_samples = spec_np.shape[0]\n",
    "    num_classes = 8\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, num_classes))\n",
    "    ranks = np.arange(1, spec_np.shape[1] + 1)\n",
    "    selected_indices = np.linspace(0, B_samples-1, num_classes, dtype=int)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        ax_spectrum.loglog(ranks, spec_np[idx], color=colors[i], alpha=0.8, linewidth=2.0)\n",
    "    ax_spectrum.axvline(x=10, color='gray', linestyle=':', linewidth=2.5)\n",
    "    ax_spectrum.set_title('Spectrum (Sampled)')\n",
    "    ax_spectrum.set_xlabel('Rank')\n",
    "    ax_spectrum.set_ylabel(r'$|\\lambda_i|$')\n",
    "\n",
    "    # --- 4. Comparison C ---\n",
    "    plot_comparison_loglog(ax_comp_c, C_ref, C, r'$C_{ii}$', CH_slice)\n",
    "\n",
    "    # --- 5. Comparison H ---\n",
    "    plot_comparison_loglog(ax_comp_h, H_ref, H, r'$H_{ii}$', CH_slice)\n",
    "\n",
    "\n",
    "def main(CH_slice, h_holder_input=None, fig_title=\"Neural Collapse Spectral Analysis\"):\n",
    "    set_icml_appendix_style()\n",
    "    h_holder = h_holder_input\n",
    "    B, N, _ = h_holder.shape\n",
    "    print(f\"Processing input data: B={B}, N={N}\")\n",
    "\n",
    "    # Baseline: Real Data\n",
    "    torch.backends.cuda.preferred_linalg_library('magma')\n",
    "    k_target_actual = min(N, 2000) \n",
    "    real_eigenvalues_orig, eigenvectors = get_top_k_decomposition(h_holder, k=k_target_actual)\n",
    "    del h_holder \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # 1. Original\n",
    "    print(\"\\n--- Processing Real Data (Original) ---\")\n",
    "    H_r_orig, C_r_orig = compute_H_C_only(real_eigenvalues_orig, eigenvectors)\n",
    "    Gap_r_orig = compute_full_gap_matrix_efficient(real_eigenvalues_orig, eigenvectors)\n",
    "    results.append({'H': H_r_orig, 'C': C_r_orig, 'Gap': Gap_r_orig, 'Spec': real_eigenvalues_orig, 'Title': \"Original\"})\n",
    "    \n",
    "    # 2. Cut @ k=1 (Tail Compression)\n",
    "    print(\"\\n--- Processing Real Data (Cut 1) ---\")\n",
    "    real_eigenvalues_smooth2 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    H_r_smooth2, C_r_smooth2 = compute_H_C_only(real_eigenvalues_smooth2, eigenvectors)\n",
    "    Gap_r_smooth2 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth2, eigenvectors)\n",
    "    results.append({'H': H_r_smooth2, 'C': C_r_smooth2, 'Gap': Gap_r_smooth2, 'Spec': real_eigenvalues_smooth2, 'Title': f\"Cut @ k=1\"})\n",
    "\n",
    "    # 3. Cut @ k=1 & Stiff Mean Collapse (MODIFIED)\n",
    "    print(\"\\n--- Processing Real Data (Stiff Mean Collapse) ---\")\n",
    "\n",
    "    real_eigenvalues_smooth3 = create_stiff_mean_spectrum(real_eigenvalues_orig, idx=1, threshold_ratio=0.001, meancollapse=False)\n",
    "    \n",
    "    H_r_smooth3, C_r_smooth3 = compute_H_C_only(real_eigenvalues_smooth3, eigenvectors)\n",
    "    Gap_r_smooth3 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth3, eigenvectors)\n",
    "    results.append({'H': H_r_smooth3, 'C': C_r_smooth3, 'Gap': Gap_r_smooth3, 'Spec': real_eigenvalues_smooth3, 'Title': f\"Cut @ k=1 & Stiff Preserve\"})\n",
    "\n",
    "\n",
    "    # 4. Cut @ k=10 & Stiff Mean Collapse (MODIFIED)\n",
    "    print(\"\\n--- Processing Real Data (Cut 10 & Stiff Mean Collapse) ---\")\n",
    "    real_eigenvalues_smooth4 = create_stiff_mean_spectrum(real_eigenvalues_orig, idx=1, threshold_ratio=0.001,meancollapse=True)\n",
    "    H_r_smooth4, C_r_smooth4 = compute_H_C_only(real_eigenvalues_smooth4, eigenvectors)\n",
    "    Gap_r_smooth4 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth4, eigenvectors)\n",
    "    results.append({'H': H_r_smooth4, 'C': C_r_smooth4, 'Gap': Gap_r_smooth4, 'Spec': real_eigenvalues_smooth4, 'Title': f\"Cut @ k=1 & Stiff Mean Collapse\"})\n",
    "\n",
    "    # Plotting\n",
    "    total_rows = len(results)\n",
    "    print(f\"\\nGenerating Plots...\")\n",
    "    fig, axes = plt.subplots(total_rows, 5, figsize=(24, 5.0 * total_rows), constrained_layout=True)\n",
    "    if total_rows == 1: axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        analyze_slope_and_plot(CH_slice,\n",
    "            res['H'], res['C'], res['Gap'], res['Spec'], res['Title'],\n",
    "            H_r_orig, C_r_orig, \n",
    "            axes[i, 0], axes[i, 1], axes[i, 2], axes[i, 3], axes[i, 4],\n",
    "            end_idx=k_target_actual)\n",
    "    \n",
    "    fig.suptitle(fig_title, fontsize=28, fontweight='bold', fontfamily='serif')\n",
    "    \n",
    "\n",
    "    save_dir = \"ICML_Figures/Ablation\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Spectrum_stiff_mean_ablation.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    print(f\"Saving to {save_path} ...\")\n",
    "    plt.savefig(save_path, format='pdf', bbox_inches='tight', pad_inches=0.2, dpi=300) \n",
    "    plt.show()\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'h_holder' in locals():\n",
    "        MY_TITLE = \"Effect of Stiff Sample Homogenization\"\n",
    "        CH_slice = torch.arange(0, 1500)\n",
    "        main(CH_slice, h_holder, fig_title=MY_TITLE)\n",
    "    else:\n",
    "        print(\"Wait: 'h_holder' is not defined.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
