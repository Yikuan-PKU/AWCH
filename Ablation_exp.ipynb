{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9321bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_config\n",
    "import torch\n",
    "import os\n",
    "\n",
    "max_e = 150 #####  task idxs\n",
    "sample_number = 20    ## number of samples used to compute AWCH\n",
    "train_size =2000 ## number of training samples per class\n",
    "\n",
    "config = model_config.set_config('none',test_size = 1000, train_size = train_size, max_epoch=max_e)\n",
    "config['add_regulization'] = False\n",
    "config['beta'] = 10\n",
    "config['lss_fn'] = 'cse'\n",
    "config['dataset'] = 'cifar10'  # 'mnist'  #'cifar10'  \n",
    "config['model'] = 'MLP' # 'CNN'  #'FC' #'CNN' \n",
    "config['sample_holder'] = [0,1,2,3,4,5,6,7,8,9]  ## the samples used to compute AWCH\n",
    "config['class_number'] = 10\n",
    "config['B'] = 100 # 30\n",
    "config['alpha'] = 0.1 # 0.5\n",
    "net_size = 1000  \n",
    "\n",
    "loss_fn = config['lss_fn']\n",
    "sample_num  = config['train_size']\n",
    "sample_holder = config['sample_holder']\n",
    "mis_label_prob = config['rho']\n",
    "\n",
    "batch_size = config['B']\n",
    "# config['sample_holder'] = []\n",
    "# config['class_number'] = \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "load_path = f\"./AWCH_data/TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}/h_g_tensors_holder_epoch_{config['max_epoch']}.pt\"\n",
    "load_path = f\"./AWCH_data/NS{net_size}_TrainSize{train_size}_SampleN{sample_number}_ClassN{len(config['sample_holder'])}_B{config['B']}lr{config['alpha']}_lossfn_{config['lss_fn']}_model_{config['model']}_dataset_{config['dataset']}/h_g_tensors_holder_epoch_{config['max_epoch']}.pt\"\n",
    "print(f\"Loading data from: {load_path}\")\n",
    "loaded_data = torch.load(load_path,weights_only=False)\n",
    "h_holder= loaded_data['h_holder']\n",
    "g_holder= loaded_data['g_holder']\n",
    "components= loaded_data['components']\n",
    "Covar = loaded_data['Covar']\n",
    "Hessian = loaded_data['matrix']\n",
    "del loaded_data\n",
    "components = torch.tensor(components).to(device)\n",
    "h_holder = torch.tensor(h_holder).to(device)\n",
    "h_holder = components @ h_holder @ components.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_icml_appendix_style():\n",
    "\n",
    "    plt.rcParams.update({\n",
    "\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'stix', \n",
    "        \n",
    "        'font.size': 18,\n",
    "        'axes.labelsize': 20,\n",
    "        'axes.titlesize': 22,\n",
    "        'xtick.labelsize': 16,\n",
    "        'ytick.labelsize': 16,\n",
    "        'legend.fontsize': 16,\n",
    "        \n",
    "\n",
    "        'lines.linewidth': 3.0,\n",
    "        'lines.markersize': 8,\n",
    "        'axes.linewidth': 2.0,\n",
    "        \n",
    "\n",
    "        'xtick.major.size': 8,\n",
    "        'xtick.major.width': 1.5,\n",
    "        'ytick.major.size': 8,\n",
    "        'ytick.major.width': 1.5,\n",
    "\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.4,\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.linewidth': 1.0,\n",
    "\n",
    "        'savefig.dpi': 300,\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "def format_boxed_ax(ax):\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.0)\n",
    "        spine.set_color('black')\n",
    "    ax.tick_params(direction='in', width=1.5, length=6, colors='black', grid_alpha=0.4)\n",
    "\n",
    "\n",
    "\n",
    "def get_top_k_decomposition(h_holder, k=800):\n",
    "    print(f\"1. Performing Eigen Decomposition (Full Rank)...\")\n",
    "    h_holder = h_holder.to(device)\n",
    "    vals, vecs = torch.linalg.eigh(h_holder)\n",
    "    vals = torch.flip(vals, dims=[1])\n",
    "    vecs = torch.flip(vecs, dims=[2])\n",
    "    N = vals.shape[1]\n",
    "    actual_k = min(k, N)\n",
    "    print(f\"2. Filtering Top {actual_k} modes...\")\n",
    "    vals_k = vals[:, :actual_k]\n",
    "    vecs_k = vecs[:, :, :actual_k]\n",
    "    del vals, vecs\n",
    "    torch.cuda.empty_cache()\n",
    "    return vals_k, vecs_k\n",
    "\n",
    "def compute_H_C_only(eigenvalues, eigenvectors, chunk_size=16):\n",
    "    N_samples = eigenvalues.shape[0]\n",
    "    N_dim = eigenvectors.shape[1]\n",
    "    H_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "    C_mean_accumulator = np.zeros(N_dim, dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, N_samples, chunk_size):\n",
    "            end_idx = min(i + chunk_size, N_samples)\n",
    "            lam_chunk = eigenvalues[i:end_idx]\n",
    "            vec_chunk = eigenvectors[i:end_idx]\n",
    "            vec_chunk = torch.flip(vec_chunk, dims=[1]) \n",
    "            V_sq_chunk = vec_chunk ** 2\n",
    "            \n",
    "            H_batch_chunk = torch.matmul(V_sq_chunk, lam_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "            lam_sq_chunk = lam_chunk ** 2\n",
    "            C_batch_chunk = torch.matmul(V_sq_chunk, lam_sq_chunk.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            H_mean_accumulator += torch.sum(H_batch_chunk, dim=0).cpu().numpy()\n",
    "            C_mean_accumulator += torch.sum(C_batch_chunk, dim=0).cpu().numpy()\n",
    "            \n",
    "            del lam_chunk, vec_chunk, V_sq_chunk, H_batch_chunk, C_batch_chunk\n",
    "            \n",
    "    return H_mean_accumulator / N_samples, C_mean_accumulator / N_samples\n",
    "\n",
    "# def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "#     print(f\"Computing Gap Matrix (Batch Size={batch_size})...\")\n",
    "#     B, N, num_modes = eigenvectors.shape \n",
    "#     eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "#     total_gap_sum = torch.zeros((N, num_modes), device=device)\n",
    "#     with torch.no_grad():\n",
    "#         for b_start in range(0, B, batch_size):\n",
    "#             b_end = min(b_start + batch_size, B)\n",
    "#             vec_chunk = eigenvectors[b_start:b_end] \n",
    "#             val_chunk = eigenvalues[b_start:b_end]      \n",
    "#             lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "#             V_sq = vec_chunk ** 2\n",
    "#             numerator = torch.cumsum(lam_sq * V_sq, dim=2) \n",
    "#             total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "#             denominator = total_energy \n",
    "#             gap_chunk = numerator / denominator \n",
    "#             total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "#             del vec_chunk, val_chunk, lam_sq, V_sq, numerator, denominator, gap_chunk\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "#     avg_gap_matrix = total_gap_sum / B\n",
    "#     return avg_gap_matrix.cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_full_gap_matrix_efficient(eigenvalues, eigenvectors, batch_size=32):\n",
    "    print(f\"Computing Gap Matrix (High Precision, Batch Size={batch_size})...\")\n",
    "    B, N, num_modes = eigenvectors.shape \n",
    "    eigenvectors = torch.flip(eigenvectors, dims=[1])\n",
    "    \n",
    "    total_gap_sum = torch.zeros((N, num_modes), device=device, dtype=torch.float64)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b_start in range(0, B, batch_size):\n",
    "            b_end = min(b_start + batch_size, B)\n",
    "            \n",
    "            vec_chunk = eigenvectors[b_start:b_end].to(torch.float64) \n",
    "            val_chunk = eigenvalues[b_start:b_end].to(torch.float64)\n",
    "            \n",
    "            lam_sq = (val_chunk ** 2).unsqueeze(1)\n",
    "            V_sq = vec_chunk ** 2\n",
    "            \n",
    "            energy_contribution = lam_sq * V_sq\n",
    "            numerator = torch.cumsum(energy_contribution, dim=2) \n",
    "            \n",
    "            total_energy = numerator[:, :, -1].unsqueeze(2)\n",
    "            \n",
    "            gap_chunk = numerator / (total_energy) \n",
    "            \n",
    "            total_gap_sum += torch.sum(gap_chunk, dim=0)\n",
    "            \n",
    "            del vec_chunk, val_chunk, lam_sq, V_sq, numerator, total_energy, gap_chunk\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_gap_matrix = total_gap_sum / B\n",
    "    return avg_gap_matrix.cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_gap_from_real_spectrum(eigenvalues, idx = 10):\n",
    "\n",
    "    gap_spectrum = eigenvalues.clone()\n",
    "    gap_spectrum[:, idx:] = gap_spectrum[:, idx:] * 1e-5\n",
    "    return gap_spectrum\n",
    "\n",
    "def create_stiff_mean_spectrum(eigenvalues, idx=1, threshold_ratio=0.1, meancollapse=False):\n",
    "\n",
    "    new_spectrum = eigenvalues.clone()\n",
    "    new_spectrum[:, idx:] = new_spectrum[:, idx:] * 1e-5\n",
    "    \n",
    "\n",
    "    lam_0 = new_spectrum[:, 0]\n",
    "\n",
    "    threshold = torch.max(lam_0) * threshold_ratio\n",
    "    \n",
    "    stiff_mask = lam_0 > threshold\n",
    "    non_stiff_mask = ~stiff_mask\n",
    "\n",
    "    if stiff_mask.sum() > 0 and meancollapse:\n",
    "        stiff_mean = torch.mean(lam_0[stiff_mask])\n",
    "        print(f\"   [Stiff Analysis] Threshold: {threshold:.4f}, Count: {stiff_mask.sum().item()}/{len(lam_0)}, Mean Val: {stiff_mean:.4f}\")\n",
    "\n",
    "        new_spectrum[stiff_mask, 0] = stiff_mean\n",
    "    if non_stiff_mask.sum() > 0:\n",
    "\n",
    "        print(f\"   [Stiff Analysis] Suppressing {non_stiff_mask.sum().item()} Non-Stiff samples by 1e-5.\")\n",
    "        new_spectrum[non_stiff_mask, 0] = new_spectrum[non_stiff_mask, 0] * 1e-3\n",
    "        \n",
    "    return new_spectrum\n",
    "\n",
    "\n",
    "\n",
    "def plot_comparison_loglog(ax, data_orig, data_new, label_name, CH_slice):\n",
    "    format_boxed_ax(ax)\n",
    "    x = data_orig[CH_slice]\n",
    "    y = data_new[CH_slice]\n",
    "    \n",
    "    mask = (x > 0) & (y > 0)\n",
    "    x_clean, y_clean = x[mask], y[mask]\n",
    "\n",
    "    if len(x_clean) > 1:\n",
    "        log_x, log_y = np.log10(x_clean), np.log10(y_clean)\n",
    "        slope, intercept, r_val, _, _ = linregress(log_x, log_y)\n",
    "        \n",
    "        ax.scatter(x_clean, y_clean, s=3, facecolors='none', edgecolors='#1f77b4', \n",
    "                   alpha=0.7, linewidth=0.5, label='Data Points')\n",
    "        \n",
    "        fit_y = 10**(intercept + slope * log_x)\n",
    "        ax.plot(x_clean, fit_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: slope={slope:.2f}')\n",
    "        \n",
    "        min_val = min(x_clean.min(), y_clean.min())\n",
    "        max_val = max(x_clean.max(), y_clean.max())\n",
    "        ref_line = np.linspace(min_val, max_val, 100)\n",
    "        ax.plot(ref_line, ref_line, 'k--', linewidth=2.0, alpha=0.6, label='y=x')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(f'Original {label_name}')\n",
    "    ax.set_ylabel(f'Current {label_name}')\n",
    "    ax.set_title(f'{label_name} Comparison')\n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.9, edgecolor='black', fancybox=False)\n",
    "\n",
    "\n",
    "def analyze_slope_and_plot(CH_slice, H, C, gap_matrix, spectrum_data, row_title, \n",
    "                           H_ref, C_ref, \n",
    "                           ax_scatter, ax_gap, ax_spectrum, ax_comp_c, ax_comp_h,\n",
    "                           end_idx=800):\n",
    "    \n",
    "    # --- 1. C_ii vs H_ii Scatter ---\n",
    "    format_boxed_ax(ax_scatter)\n",
    "    x_data = H[CH_slice]\n",
    "    y_data = C[CH_slice]\n",
    "    mask = (x_data > 0) & (y_data > 0)\n",
    "    x_data, y_data = x_data[mask], y_data[mask]\n",
    "    \n",
    "    if len(x_data) > 1:\n",
    "        log_x, log_y = np.log10(x_data), np.log10(y_data)\n",
    "        slope, intercept, _, _, _ = linregress(log_x, log_y)\n",
    "        ax_scatter.scatter(x_data, y_data, s=3, alpha=0.6, color='#000080', label='Data', edgecolors='none')\n",
    "        fit_line_y = 10**(intercept + slope * log_x)\n",
    "        ax_scatter.plot(x_data, fit_line_y, color='#d62728', linestyle='-', linewidth=1.0, label=f'Fit: {slope:.2f}')\n",
    "        \n",
    "        mid_x, mid_y = np.mean(log_x), np.mean(log_y)\n",
    "        ref_line_x = np.logspace(min(log_x), max(log_x), 100)\n",
    "        ref_line_y1 = 10**(1.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y1, 'k--', linewidth=2.0, label='Slope=1')\n",
    "        ref_line_y2 = 10**(2.0 * (np.log10(ref_line_x) - mid_x) + mid_y)\n",
    "        ax_scatter.plot(ref_line_x, ref_line_y2, color='green', linestyle=':', linewidth=3.0, label='Slope=2')\n",
    "    \n",
    "    ax_scatter.set_xscale('log')\n",
    "    ax_scatter.set_yscale('log')\n",
    "    ax_scatter.set_xlabel(r'$H_{ii}$')\n",
    "    ax_scatter.set_ylabel(r'$C_{ii}$')\n",
    "    ax_scatter.set_title(f\"Scalability ({row_title})\", fontweight='bold') \n",
    "    ax_scatter.legend(loc='upper left', frameon=True, edgecolor='black', fancybox=False)\n",
    "    \n",
    "    # --- 2. Gap Curve ---\n",
    "    format_boxed_ax(ax_gap)\n",
    "    real_k = gap_matrix.shape[1]\n",
    "    k_values = np.arange(1, real_k + 1)\n",
    "    avg_gap_curve = np.mean(gap_matrix[:1500], axis=0)\n",
    "    \n",
    "    indices_to_plot = [1, 10, 50, 100, 400, 1000]\n",
    "    colors_gap = plt.cm.viridis(np.linspace(0, 0.9, len(indices_to_plot))) \n",
    "    for idx, color in zip(indices_to_plot, colors_gap):\n",
    "        if idx < gap_matrix.shape[0]:\n",
    "            ax_gap.semilogx(k_values, gap_matrix[idx, :], color=color, linewidth=2.0, alpha=0.8, label=f'i={idx+1}')\n",
    "    ax_gap.semilogx(k_values, avg_gap_curve, 'k--', linewidth=3.5, alpha=1.0, label='Avg')\n",
    "    ax_gap.legend(loc='lower right', ncol=2, frameon=True, edgecolor='black', fancybox=False) \n",
    "    ax_gap.set_title(\"Gap Metric\")\n",
    "    ax_gap.set_xlabel('k (Cutoff)')\n",
    "    ax_gap.set_ylabel('Cum. Distribution')\n",
    "    ax_gap.set_ylim(-0.05, 1.1)\n",
    "    \n",
    "    # --- 3. Spectrum Plot ---\n",
    "    format_boxed_ax(ax_spectrum)\n",
    "    if isinstance(spectrum_data, torch.Tensor):\n",
    "        spec_np = spectrum_data.detach().cpu().numpy()\n",
    "    else:\n",
    "        spec_np = spectrum_data\n",
    "    B_samples = spec_np.shape[0]\n",
    "    num_classes = 8\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, num_classes))\n",
    "    ranks = np.arange(1, spec_np.shape[1] + 1)\n",
    "    selected_indices = np.linspace(0, B_samples-1, num_classes, dtype=int)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        ax_spectrum.loglog(ranks, spec_np[idx], color=colors[i], alpha=0.8, linewidth=2.0)\n",
    "    ax_spectrum.axvline(x=10, color='gray', linestyle=':', linewidth=2.5)\n",
    "    ax_spectrum.set_title('Spectrum (Sampled)')\n",
    "    ax_spectrum.set_xlabel('Rank')\n",
    "    ax_spectrum.set_ylabel(r'$|\\lambda_i|$')\n",
    "\n",
    "    # --- 4. Comparison C ---\n",
    "    plot_comparison_loglog(ax_comp_c, C_ref, C, r'$C_{ii}$', CH_slice)\n",
    "\n",
    "    # --- 5. Comparison H ---\n",
    "    plot_comparison_loglog(ax_comp_h, H_ref, H, r'$H_{ii}$', CH_slice)\n",
    "\n",
    "\n",
    "def main(CH_slice, h_holder_input=None, fig_title=\"Neural Collapse Spectral Analysis\"):\n",
    "    set_icml_appendix_style()\n",
    "    h_holder = h_holder_input\n",
    "    B, N, _ = h_holder.shape\n",
    "    print(f\"Processing input data: B={B}, N={N}\")\n",
    "\n",
    "    # Baseline: Real Data\n",
    "    torch.backends.cuda.preferred_linalg_library('magma')\n",
    "    k_target_actual = min(N, 2000) \n",
    "    real_eigenvalues_orig, eigenvectors = get_top_k_decomposition(h_holder, k=k_target_actual)\n",
    "    del h_holder \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # 1. Original\n",
    "    print(\"\\n--- Processing Real Data (Original) ---\")\n",
    "    H_r_orig, C_r_orig = compute_H_C_only(real_eigenvalues_orig, eigenvectors)\n",
    "    Gap_r_orig = compute_full_gap_matrix_efficient(real_eigenvalues_orig, eigenvectors)\n",
    "    results.append({'H': H_r_orig, 'C': C_r_orig, 'Gap': Gap_r_orig, 'Spec': real_eigenvalues_orig, 'Title': \"Original\"})\n",
    "    \n",
    "    # 2. Cut @ k=1 (Tail Compression)\n",
    "    print(\"\\n--- Processing Real Data (Cut 1) ---\")\n",
    "    real_eigenvalues_smooth2 = create_gap_from_real_spectrum(real_eigenvalues_orig, idx=1)\n",
    "    H_r_smooth2, C_r_smooth2 = compute_H_C_only(real_eigenvalues_smooth2, eigenvectors)\n",
    "    Gap_r_smooth2 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth2, eigenvectors)\n",
    "    results.append({'H': H_r_smooth2, 'C': C_r_smooth2, 'Gap': Gap_r_smooth2, 'Spec': real_eigenvalues_smooth2, 'Title': f\"Cut @ k=1\"})\n",
    "\n",
    "    # 3. Cut @ k=1 & Stiff Mean Collapse (MODIFIED)\n",
    "    print(\"\\n--- Processing Real Data (Stiff Mean Collapse) ---\")\n",
    "\n",
    "    real_eigenvalues_smooth3 = create_stiff_mean_spectrum(real_eigenvalues_orig, idx=1, threshold_ratio=0.001, meancollapse=False)\n",
    "    \n",
    "    H_r_smooth3, C_r_smooth3 = compute_H_C_only(real_eigenvalues_smooth3, eigenvectors)\n",
    "    Gap_r_smooth3 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth3, eigenvectors)\n",
    "    results.append({'H': H_r_smooth3, 'C': C_r_smooth3, 'Gap': Gap_r_smooth3, 'Spec': real_eigenvalues_smooth3, 'Title': f\"Cut @ k=1 & Stiff Preserve\"})\n",
    "\n",
    "\n",
    "    # 4. Cut @ k=10 & Stiff Mean Collapse (MODIFIED)\n",
    "    print(\"\\n--- Processing Real Data (Cut 10 & Stiff Mean Collapse) ---\")\n",
    "    real_eigenvalues_smooth4 = create_stiff_mean_spectrum(real_eigenvalues_orig, idx=1, threshold_ratio=0.001,meancollapse=True)\n",
    "    H_r_smooth4, C_r_smooth4 = compute_H_C_only(real_eigenvalues_smooth4, eigenvectors)\n",
    "    Gap_r_smooth4 = compute_full_gap_matrix_efficient(real_eigenvalues_smooth4, eigenvectors)\n",
    "    results.append({'H': H_r_smooth4, 'C': C_r_smooth4, 'Gap': Gap_r_smooth4, 'Spec': real_eigenvalues_smooth4, 'Title': f\"Cut @ k=1 & Stiff Mean Collapse\"})\n",
    "\n",
    "    # Plotting\n",
    "    total_rows = len(results)\n",
    "    print(f\"\\nGenerating Plots...\")\n",
    "    fig, axes = plt.subplots(total_rows, 5, figsize=(24, 5.0 * total_rows), constrained_layout=True)\n",
    "    if total_rows == 1: axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        analyze_slope_and_plot(CH_slice,\n",
    "            res['H'], res['C'], res['Gap'], res['Spec'], res['Title'],\n",
    "            H_r_orig, C_r_orig, \n",
    "            axes[i, 0], axes[i, 1], axes[i, 2], axes[i, 3], axes[i, 4],\n",
    "            end_idx=k_target_actual)\n",
    "    \n",
    "    fig.suptitle(fig_title, fontsize=28, fontweight='bold', fontfamily='serif')\n",
    "    \n",
    "\n",
    "    save_dir = \"ICML_Figures/Ablation\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"Spectrum_stiff_mean_ablation.pdf\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    print(f\"Saving to {save_path} ...\")\n",
    "    plt.savefig(save_path, format='pdf', bbox_inches='tight', pad_inches=0.2, dpi=300) \n",
    "    plt.show()\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'h_holder' in locals():\n",
    "        MY_TITLE = \"Effect of Stiff Sample Homogenization\"\n",
    "        CH_slice = torch.arange(0, 1500)\n",
    "        main(CH_slice, h_holder, fig_title=MY_TITLE)\n",
    "    else:\n",
    "        print(\"Wait: 'h_holder' is not defined.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
